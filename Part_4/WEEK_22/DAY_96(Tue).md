# DAY 96

## 목차
- [WebClient](#webclient)
- [비동기 처리 적용 타이밍](#비동기-처리-적용-타이밍)
- [캐시](#캐시)
- [Spring Cache](#spring-cache)
- [로컬 캐시](#로컬-캐시)

---

## WebClient
#### HTTP 요청
- 구성
  + WebClient 인스턴스
  + HTTP 메서드 선택
  + uri 설정
  + header 설정
  + 요청 전송

- RequestHeadersSpec
  + WebClient 요청 구성 단계 중 하나를 나타내는인터페이스
  + WebClient가 요청을 완성하기 전의 중간 빌더 객체
  + RequestBodySpec : 요청 본문을 설정할 수 있는 단계
  + RequestHeadersSpec<?> : 헤더와 URI, 메서드를 포함한 완성된 요청 상태
    + HTTP 요청이 완성된 상태를 표현하는 객체이며
    + 아직 전송되지 않은 빌더 패턴의 마지막 단계
   
#### 응답 처리
- WebClient 요청 전송 후 Mono<ClientResponse> 형태의 응답을 비동기로 반환
  + retrieve() : 요청 전송, 응답 상태 코드 검증 및 바디 추출 준비
  + bodyToMono() / bodyToFlux() : 실제 응답 본문을 역직렬화
  + 여러 데이터(리스트)를 반환하는 경우에는 bodyToFlux() 사용 - 컬렉션 응답
 
- 응답 처리 방식
  - retrieve()
    + 반환 타입 : ResponseSpec
    + 일반적인 응답 본문 처리 목적
    + 상태 코드 4xx/5xx 시 예외 발생
    + BodyToMono() / bodyToFlux()와 함께 사용
  - exchangeToMono()
    + 반환 타입 : Mono<ClientResponse>
    + 상태코드 / 헤더를 세밀하게 다뤄야할 때 사용
    + 예외 발생 x (직접 처리 필요)
    + 로깅, 조건부 응답, 헤더 기반 처리
   
  - 예외 처리
    - retrieve() 4xx/5xx 응답 시 자동으로 예외 발생
      + 이를 커스터마이징 하려면 .onStatus( status -> status.is4xxClientError(), response -> response.~)
        + is5xxServerError()
    - onErrorResume : 예외 발생 시 대체 데이터를 반화할 때 유용
   
#### 고급 기능
- 문제 상황
  + 네트워크 지연 : 서버가 응답하지 않거나 매우 느린 경우
  + 서버 장애 : 일시적으로 5xx 오류 발생
  + 일시적 연결 오류 : DNS 문제나 연결 끊김 등 일시적 실패
  + 요청 과부화 : 여러 요청이 동시에 발생해 리소스 고갈
 
- 타임아웃 : 특정 시간 안에 응답이 없을 경우 요청을 강제로 종료하는 메커니즘
- 재시도 : 일시적인 실패 시 동일 요청을 일정 횟수만큼 자동으로 재전송하는 기능
- 서킷 브레이커 : 지속적인 실패를 감지하면 일시적으로 요청을 차단하여 시스템의 연쇄 장애를 방지하는 패턴
  + resilience4j를 사용
- 동시 요청 처리 : 논블로킹 구조를 활용하여 여러 요청을 동시에 병렬로 처리할 수 있음

## 비동기 처리 적용 타이밍
- 비동기 처리는 응답 속도를 단축하거나 병렬로 여러 작업을 동시에 수행하기 위해 필요
- 비동기 방식은 요청을 분리하여 CPU와 IO 리소스를 효율적으로 사용할 수 있음
- 적합한 사용 사례
  + IO 중심 작업
  + 병렬 처리 가능한 작업
  + 사용자 응답 우선 상황
  + 백그라운드 후처리 작업
 
- 부적합한 사용 사례
  + 트랜잭션이 필요한 작업
  + 순서가 중요한 로직
  + 공유 자원 접근이 잦은 작업 : 동시성 문제
  + 결과가 즉시 필요한 작업

- **fire-and-forget**
  - 결과를 기다리지 않는 비동기 처리 방식
    + 주로 응답이 void인 경우
    + 응답 속도가 중요한 사용자 경험 중심의 서비스(UI 응답, 로그 기록, 알림 등)에 적합
 
- **비동기 결과 결합 패턴**
  - 여러 비동기 작업을 동시에 수행한 뒤, 모든 결과가 완료되면 하나의 결과로 합치는 방식
  - API 응답을 여러 외부 서비스에서 가져와 통합 데이터를 구성할 때 유용
  - Mono.zip()은 여러 비동기 요청을 동시에 실행하고, 모든 요청이 완료되면 결과를 결합
 
- **배치 처리 패턴**
  - 다수의 비동기 작업을 일정 단위로 묶어 한번에 실행하는 방식
  - 대규모 데이터나 반복성 작업에 적합
    + 시스템 리소스를 효율적으로 활용할 수 있음
   
- **비동기 모니터링**
  - 비동기적으로 실행되는 작업은 눈에 보이지 않음
    + 문제가 생기더라도 인지하기 어려움 -> 모니터링의 중요성
  - 필요성
    + 가시성 수정 : 비동기 작업은 별도의 스레드나 큐에서 처리되어, 로그나 트레이싱이 없으면 상태를 알 수 없음
    + 자원 고갈 : 스레드 풀 크기 초과나 큐 적체로 인해 새로운 작업이 지연되거나 실패할 수 있음
    + 장애 전파 : 비동기 처리 실패가 다른 서비스에 영향을 줄 수 있음
    + 추적 어려움 : 작업 실행 흐름이 분리되어 있어 로그만으로 원인 분석이 어려움
   
## 캐시
- 자주 접근하는 데이터를 빠르게 가져오기 위해 임시로 저장해두는 저장소
- 짧은 시간에 수많은 사용자가 동시에 요청을 보내는 상황
  + DB로 향하는 요청량을 크게 줄이고, 시스템 전체가 안정적으로 작동할 수 있게 함
- 주요 목적
  + 자주 접근하는 데이터의 빠른 검색
    + 데이터베이스를 거치지 않기 때문에 네트워크 왕복 시간과 쿼리 실행 시간을 절약
  + 원본 데이터 소스의 부하 감소
    + 동일한 데이터를 여러 번 요청하더라도 DB는 한 번만 조회
    + 따라서 데이터베이스 연결 수가 급격히 증가하는 것을 방지
  + 네트워크 지연 시간 최소화
    + 사용자와 가까운 위치에 데이터를 저장하여 지연을 최소화
    + 물리적으로 가까운 곳에서 데이터를 꺼내기 때문에 응답 속도가 비약적으로 향상
   
- 필요한 곳에만 선택적으로 적용해야 함
- 변경이 자주 일어나는 데이터는 캐시보다 DB 직조회가 나을 수 있음
- 캐시 저장소로는 Redis, Memcached, Guava Cache 등이 자주 사용됨
- CDN(Content Delivery Network)은 정적 파일의 캐시를 담당하는 대표적인 예

- **캐시의 성능을 결정하는 핵심 개념**
  + 시간적 지역성
    + 최근에 사용한 데이터는 가까운 미래에도 다시 사용될 가능성이 높다는 원리
    + 최근에 접근된 데이터를 캐시에 보관하면 다시 요청될 때 즉시 응답할 수 있음
    + 시간적 지역성은 대부분의 캐시 시스템이 TTL 개념을 사용하는 이유
  + 공간적 지역성
    + 어떤 데이터가 사용되면 그 주변(인접) 데이터도 곧 사용될 가능성이 높다는 원리
    + 캐시가 하나의 데이터뿐 아니라 인접한 데이터까지 함께 저장하여 이후 요청 시 빠르게 제공할 수 있음
  + 캐시 히트와 캐시 미스
    + 캐시 히트 : 요청한 데이터가 캐시에 존재하여 즉시 응답이 가능한 경우
    + 캐시 미스 : 요청한 데이터가 캐시에 없어 DB 등 다시 조회해야 하는 경우
  + 캐시 적중률
    + 적중률 80~90 % 이상을 유지하는 것이 일반적으로 이상적
   
- **대용량 트래픽 환경 캐시의 필요성**
  - DB 부하 감소
    + 데이터베이스로 향하는 요청 수를 줄임
    + 집계 쿼리는 코스트가 매우 높음
  - 응답 시간 개선
    + 데이터를 메모리에서 바로 가져오기 때문에 응답 속도가 획기적으로 빨라짐
  - 시스템 확장성 향상
    + 시스템이 사용자 수 증가에도 성능 저하 없이 대응할 수 있는 능력
    + 캐시를 도입하면 요청이 DB에 집중되지 않고 분산되어, 더 많은 사용자를 처리할 수 있음
  - 비용 효율성 향상
    + 캐시를 통해 DB 서버 수를 줄일 수 있음
    + 네트워크 전송 비용 감소
    + 클라우드 과금 절감 효과 (I/O, 트래픽, CPU 사용량 감소)
   
- 적용 고려 사항
  - 캐시 적합 데이터 식별
    + 자주 조회되지만 자주 변경되지 않는 데이터
    - 데이터 선정 기준
      + 조회 빈도
      + 변경 빈도
      + 최신성 중요도
  - 데이터 크기와 수명 주기
    + 메모리 기반 저장소라 저장 공간은 제한적
    + 너무 큰 데이터를 저장하면 다른 캐시가 삭제되어 성능 감소
    - TTL 설정
      + 캐시 데이터의 유효 시간
      + 일정 시간이 지나면 자도응로 삭제되어, 데이터의 최신성 유지
  - 일관성과 최신성의 균형
    + 캐시 데이터와 실제 데이터가 달라지는 문제를 캐시 불일치
      + 방치하면 오래된 데이터를 보게 되거나, 잘못된 정보가 전파될 수 있음
      + 따라서 DB 변경 시점과 캐시 갱신 시점의 일관성을 유지하는 전략이 매우 중요
    - 해결 전략
      + Cache Invalidation : DB 변경 시 캐시 삭제 / 첫 요청 느림
      + Wirte-through : DB 갱신과 동시에 캐시 갱신 / 쓰기 성능 저하
      + Background Refresh : 주기적으로 캐시 재생성 / 자동 동기화 / 실시간성 부족
  - 캐시 전략 선택
    - Cache-aside(Lazy Loading)
      + 요청 시 캐시 없으면 DB 조회 후 캐시에 저장
      + 첫 요청 느림
    - Write-through
      + DB에 쓰기 시 캐시도 즉시 갱신
      + 쓰기 부하 증가
    - Wirte-behind(Write-back)
      + 캐시에 먼저 쓰고, 나중에 DB에 반영
      + 빠른 응답
      + 장애 시 데이터 유실 위험
    - Read-through
      + 캐시가 DB를 직접 조회
      + 캐시 시스템 복잡
     
#### 캐시 계층 구조

| 계층 | 위치                             | 속도         | 용량 | 주 용도                 |
|-----|--------------------------------|-------------|-----|-----------------------|
| L1  | CPU, 애플리케이션 메모리             | 매우 빠름     | 작음 | 즉시 접근 가능한 데이터 캐싱 |
| L2  | 애플리케이션 외부(Redis, Memcached) | 빠름         | 중간 | 여러 서버 간 공유 캐시      |
| L3  | CDN, DB 캐시, 프록시 서버 등        | 상대적으로 느림 | 큼   | 전역적 데이터 배포 및 캐시  |

- **L1**
  - 가장 가까운 계층
  - 프로그램이 실행 중인 프로세스에서 즉시 접근할 수 있어 지연이 거의 없음
  - 서버가 여러 대라면 각 인스턴스의 캐시가 서로 다른 데이터를 가질 수 있어 일관성이 깨질 수 잇음
 
- **L2**
  - 서버 간 공유 가능한 캐시 계층
  - Redis나 Memcached 같은 외부 캐시 서버가 해당
  - 여러 애플리케이션 인스턴스가 공유 하므로, 일관성을 유지하면서 분산 환경에서도 효율적인 캐싱이 가능
 
- **L3**
  - 글로벌 트래픽 분산 및 네트워크 지연 최소화를 위한 캐시 게층
  - CDN이나 DB Query Cache가 여기에 해당
 
- L1 -> L2 -> L3 순으로 캐시를 구성하면, 데이터 접근 속도는 빠랄지고 DB 부하는 감소

#### 캐시 토폴로지
- **로컬 캐시**
  - 애플리케이션 내부 메모리에 데이터를 저장하는 캐시 구조
  - 외부 네트워크 요청 없이 가장 빠르게 데이터에 접근할 수 있음
  - 장점 :
    + 네트워크 호출이 없어 응답 속도가 가장 빠름
    + 단순 구현 가능
    + 외부 장애에 영향받지 않음
   
  - 단점 :
    + 서버마다 캐시가 달라 데이터 불일치 가능성
    + 서버 재시작 시 캐시가 모두 초기화
    + 확장성이 나증ㅁ
   
- **분산 캐시**
  - 여러 서버 인스턴스가 동일한 캐시 서버를 공유하는 구조
    + 여러 서버가 하나의 중앙 캐시 저장소를 공유
    + 데이터 일관성 유지가 용이하며, 확장성에 유리
   
  - 장점 :
    + 여러 서버 간 데이터 공유 가능
    + 캐시 서버 장애 시에도 Persistence(데이터 영속화) 설정 가능
    + 수평 확장(Scale-Out)에 유리
   
  - 단점 :
    + 네트워크 지연이 존재
    + Redis 자앵 시 모든 요청이 DB로 몰릴 수 있음
    + 운영/모니터링 복잡도가 증가
   
- **다중 레벨 캐시**
  - L1(로컬) + L2(분산) 구조로 결합한 형태
  - 서버 내부의 빠른 접근성과 서버 간 일관성을 모두 확보하는 방식
  - 캐시 동기화 설계 복잡
  - 대규모 트래픽 + 서버 다중 인스턴스 운영 환경
  - Redis Pub/Sub 또는 이벤트 기반 캐시 무효화 전략 사용 -> 비동기로 처리 가능
 
- **특화 캐시**
  - HTTP 캐시 : 웹 애플리케이션 레벨에서 정적 콘텐츠를 캐싱하는 방식
    + Cache-Control : max-age, no-cache 등 캐시 정책 설정
    + ETag / Last-Modified : 변경 검증용 헤더로 조건부 요청 가능
    + CDN 연계 : Cloudflare, AWS CloudFront 등에서 정적 리소스 캐싱
    + 정적 자산 최적화 및 CDN 활용에 필수
   
  - ORM 캐시 : JPA/Hibernate 같은 ORM이 SQL 결과를 내부에 캐싱하여 DB접근을 최소화 하는 전략
 
#### 트래픽 패턴 분석
- 캐시의 효율성을 극대화하기 위한 첫 단계
  + 요청 빈도 : 자주 호출되면 TTL 길게, 변경 주기 낮게
  + 데이터 변경 주기 : 변경 잦으면 캐시보다 조회 최적화 우선
  + 트래픽 집중도 : 분산 캐시나 샤딩 구조 고려
  + 요청 경로 : API 단위 캐싱 설계 필요
 
#### 데이터 액세스 패턴 분석
- 데이터가 얼마나 자주 재사용되는지
  + Read-Heavy(읽기 중심) : 조회가 매우 많고 변경은 드묾 / 캐시 TTL 길게, L1/L2 구조 추천
  + Write-Heavy(쓰기 중심) : 변경이 많고 실시간성 중요 / 캐시 무효화 중심 설계
  + Balanced(균형형) : 조회와 변경이 비슷함 / DB 트랜잭션 기반 캐시 동기화 적용
 
## Spring Cache
#### Spring Cache 추상화
- 여러 종류의 캐시 구현체를 일관된 방식으로 사용할 수 있게 해주는 통합 계층
- 캐시의 내부 동작(저장 방식, 네트워크 구조 등)을 몰라도, 하나의 통합 인터페이스를 통해 다양한 캐시를 다룰 수 있음
- 목적
  + 구현체 독립성 : Cache API를 표준화하여 구현체를 쉽게 교체 가능
  + 일관된 캐시 접근 방식 : 동일한 어노테이션으로 다양한 캐시 제어
  + 선언적 캐시 관리 : 코드 내부에서 캐시 로직을 직접 작성하지 않아도 어노테이션으로 제어 가능
  + 코드 유지보수성 향상 : 비즈니스 로직과 캐시 로직을 분리하여 코드 가독성과 관리성 향상
 
- 추상화 구조 구성 요소
  + CacheManager : 캐시를 생성하고, 각 캐시 영역(Cache)을 관리
  + Cache : 캐시 데이터의 CRUD를 수행하는 인터페이스
  + CacheResolver : 여러 캐시 중 어떤 캐시를 사용할지 결정
 
- 선언적 캐시 관리
  + AOP 기반으로 자동 적용
  + 어노테이션을 붙이는 것만으로 캐시를 적용할 수 있음
  + @Cacheable : 메서드 실행 결과를 캐시에 저장하고, 캐시 존재 시 결과를 재사용
  + @CacheEvict : 특정 캐시 데이터를 삭제 (주로 업데이트 후 사용)
  + @CachePut : 메서드 실행 결과를 항상 캐시에 저장 (강제 갱신 시 사용)
  + @Caching : 여러 캐시 어노테이션을 결합하여 사용
  - 장점 :
    + 코드 단순화
    + 유지보수성 향상
    + 테스트 용이성
    + 유연한 확장성
   
#### 핵심 컴포넌트
- CacheManager
  + 캐시 저장소(Cache)를 생성하고 관리하는 관리자 역할 수행
  + 개발자가 명시적으로 캐시 객체를 만들지 않아도 CacheManager가 알아서 생성하고 관리
    + 캐시 등록 및 조회 : 지정된 이름의 캐시를 관리
    + 캐시 구현체 선택 : Caffeine, EhCache, Redis 등 다양한 구현체 지원
    + 캐시 일관성 유지 : 여러 캐시 간 데이터 일관성 관리
  + 개발 환경에 따라 적절한 CacheManager 선택 가능
 
- Cache
  + 캐시 데이터의 CRUD를 담당
  + 실제로 캐시 데이터를 저장하거나 읽어오는 작업은 Cache 객체 내부에서 이루어짐
    + get()
    + put()
    + evict()
    + clear()
   
- CacheResolver
  + 복수의 캐시가 존재하는 환경에서, 어떤 캐시를 사용할지 동적으로 결정하는 역할
  + 특정 조건에 따라 캐시 선택 로직을 커스터마이징 해야 하는 경우 직접 구현할 수 있음
 
#### 동작 원리
- 내부적으로 AOP를 이용하여 캐시 로직을 자동으로 처리
- 개발자가 직접 캐시를 조작하지 않아도 Spring이 메서드 호출 전후에 캐시 로직을 프록시로 감싸서 실행
- 캐시 키 생성 메커니즘
  - 기본적으로 SimpleKeyGenerator 사용
    + 인자 1개 : 인자 값 자체
    + 인가 여러개 : 모든 인자를 조합하여 해시
    + 인자가 없을 때 : SimpleKey.EMPTY
   
#### 주요 캐시 어노테이션
- **@Cacheable**
  - 메서드 실행 결과를 캐시에 저장
  - 동일한 인자로 호출 시 저장된 값 반환
  - condition : 캐싱을 수행할 조건 (true 일때만 저장)
  - unless : 메서드 실행 후 결과에 따라 저장 여부 결정 (true일때 동작 안함)
- **@CachePut**
  - 항상 메서드를 실행하고, 실행 결과를 캐시에 강제로 갱신
- **@CacheEvict**
  - 캐시된 데이터를 제거
  - allEntries : 전체 캐시 삭제
    + `allEntries = true`
  - beforeInvocation = true : 메서드 실행 전에 캐시 삭제
- @Caching
  - 여러 캐시 동작을 묶어서 수행
    ```java
    @Caching(
        put = {@CachePut(value = "products", key = "#product.id")},
        evict = {@CacheEvict(value = "products", key = "'list'")}
    )
    // id는 갱신하고 전체 목록을 삭제 (전체 목록은 갱신하기 어려움 -> 전체 호출 필요)
    ```
- @CacheConfig
  - 클래스 단위에서 공통 캐시 이름, 키 생성 정책 등을 지정할 수 있음
 

## 로컬 캐시
#### ConcurrentMapCacheManager
- SpringBoot에서 @EnableCaching 활성화 시 자동으로 ConcurrentMapCacheManager가 등록됨
  + 내부적으로 ConcurrentHashMap 사용
  + TTL이나 캐시 크기 제한 기능 없음
 
#### Caffeine Cache
- Guava Cache를 대체하기 위해 만들어진 고성능 인메모리 캐시 라이브러리
- ConcurrentMapCacheManager보다 다양한 기능 제공
- ```java
    @Bean
    public CacheManager caffeineCacheManager() {
        CaffeineCacheManager cacheManager = new CaffeineCacheManager("userCache");
        cacheManager.setCaffeine(Caffeine.newBuilder()
                .maximumSize(1000)                // 최대 1000개 항목 저장
                .expireAfterWrite(10, TimeUnit.MINUTES)  // 쓰기 후 10분 만료
                .recordStats());                 // 통계 수집 활성화
        return cacheManager;
    }
  ```
- 주요 기능 요약
  + 만료 정책 : expireAfterWrite, expireAfterAccess 등 지원
  + 크기 제한 : maximumSize()로 항목 수 제한
  + 통계 수집 : recordStats() 로 hit/miss 비율 추적
  + 성능 : ConcurrentMapCache보다 3~5배 빠름
  + 사용 용도 : 실시간 데이터 캐싱, 조회 빈도 높은 데이터
 
#### EhCache
- Java 진영에서 오래된 캐시 솔루션
- Spring Boot와의 통합도 간단하며 XML 또는 JavaConfig 방식으로 설정할 수 있음
- 특징
  + 저장 매체 : 메모리 + 디스크 (선택ㅈ적)
  + 만료 정책 : TTL, TTI 지원
  + 클러스터링 : 다중 노드 간 동기화 가능
  + 적합한 환경 : 대규모 데이터 캐싱, 서버 간 데이터 공유
- 로컬 캐시지만, 디스크 기반 스왑 기능으로 메모리 부담을 줄일 수 있음
- 다중 서버 간 동기화 옵션을 활성화하면 Redis 대체로 활용 가능하지만, 설정 복잡도가 높음

#### 구성 최적화
- 무한정 데이터를 쌓을 경우 메모리 과다 사용으로 이어짐
- 크기 제한, 만료 정책, 제거 이벤트 처리를 적절히 조합해야 함
- 발생 가능한 문제
  - OutOfMemoryError
  - 오래된 데이터 유지로 인한 불일치 문제
  - 캐시 적중률 하락으로 인한 불필요한 DB 부하
 
- 크기 제한의 필요성
  - JVM 힙 메모리를 점점 압박하여 GC 부하 및 시스템 지연을 초래할 수 있음
  - maximumSize() 또는 maximumWeight()(CoustomWeight 설정 필요) 옵션 설정
  - 너무 작은 크기는 적중률을 떨어트리고, 너무 큰 크기는 GC 부하를 유발
 
- 만료 정책 설정
  - 오래된 데이터를 자동으로 정리
  - 시간 기반 만료
    + 시간을 기준으로 캐시 항목을 자동 제거하는 정책
  - 접근 기반 만료
    + 최근 접근이 많았던 데이터를 우선 보관하고, 오래 접근하지 않은 데이터를 제거
    + LRU 방식으로 작동
    + +LRU : 최근 접근 시간 / 최근 사용한 항목은 유지, 오래된 항목 제거
    + +LFU : 접근 횟수 / 자주 사용된 항목 유지, 거의 접근하지 않은 항목 제거
  - 정적 데이터는 시간 기반 만료
  - 사용자 세션/토큰 등은 접근 기반 만료
 
- 캐시 항목 제거 리스너
  - 제거 이벤트 감지
    + 캐시 항목이 제거될 때 후처리를 수행해야 하는 경우
      + ex: DB 동기화, 로그 기록, 또는 이벤트 알림 같은 작업
    + Caffeine의 removalListener() 활용
      + 제거원인 :
        + EXPLICIT : 명시적 제거 (ex: @CacheEvict 호출)
        + REPLACED : 새로운 값으로 대체됨
        + COLLECTED : GC에 의해 수거됨
        + EXPIRED : TTL이 만료되어 제거됨
        + SIZE : 크기 제한 초과로 제거됨
       
#### 성능 측정
- 핵심 지표
  + Hit Ratio : 적중률 / 캐시에서 데이터를 성공적으로 가져온 비율
  + Miss Ratio : 미적중률 / 캐시에 데이터가 없어 원본 데이터 소스를 조회한 비율
  + Eviction Count : 제거 횟수 / 캐시 용량과 초과나 만료로 인해 제거된 항목의 수
 
- 기준값
  + 우수 : 90% 이상
  + 보통 : 70%~ / 일부 요청이 캐시되지 않음
  + 낮음 : 70% 미만 / 만료 시간, 키 전략등 정책 재점검 필요
  + 너무 높은 적중률은 오래된 데이터가 남아 있을 가능성을 의미하기도 함
 
- 크기와 성능 상관관계
  + 캐시 크기 up -> 메모리 사용량 up -> 적중률 up -> 평균 응답속도 down
  + 일정 수준 이후에는 캐시 크기를 키워도 효과가 미미함 -> 적중률은 비슷하지만 메모리 사용량이 급증
 
- 메모리 사용량 모니터링
  - 캐시를 과도하게 사용하면 JVM Heap이 빠르게 소모될 수 있음
  - 이를 방지하기 위해 GC 로그와 메모리 사용량을 함께 추적해야 함
  - JVisualVM 활용
