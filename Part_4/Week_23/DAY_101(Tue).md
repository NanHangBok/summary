# DAY_101

## 대용량 트래픽 관리 정리

### 동기 비동기
- **동기(Synchronous)**
  - 요청한 작업이 끝날 때까지 다음 작업이 대기
  - ex: 순차적 코드 실행
 
- **비동기(Asynchronous)**
  - 요청한 작업의 완료 여부와 관계없이 다음 작업을 수행
  - ex: 병렬적으로 여러 작업 수행
 
### 블로킹 논 블로킹
- **블로킹**
  - 호출한 함수가 작업을 끝낼 때까지 제어권을 반환하지 않음
  - 작업 온료 후 제어권 반혼
 
- **논블로킹**
  - 호출 즉시 제어권을 반환하며, 완료 여부는 나중에 확인
  - 즉시 제어권 반환
 
### 동기/비동기 + 블로킹/논블로킹 조합
| 구분           | 제어 흐름                               | 스레드 상태           | 대표 예시                 |
|---------------|---------------------------------------|-------------------|-------------------------|
| 동기 + 블로킹    | 작업 완료까지 기다림                       | 제어권 반환 X        | Thread.sleep()          |
| 동기 + 논블로킹   | 결과를 반복 확인 (Polling)                | 제어권 즉시 반환      | NIO Channel + while 루프 |
| 비동기 + 블로킹   | 별도 스레드에서 실행하지만, 호출자는 결과 기다림  | Future.get()      |                         |
| 비동기 + 논블로킹 | 별도 스레드에서 실행되고 결과는 콜백으로 전달     | CompletableFuture |                         |

### 스레드 동작 구조
- MainThread -> 비동기 작업 요청 -> WorkerThread
- WorkThread -> 즉시 제어권 반환 -> MainThread
- MainThread -> 다른작업 수행 -> MainThread
- WorkThread -> 작업 완료 통보(콜백) -> MainThread

### 성능 관점에서의 차이
| 비교 항목   | 동기 처리                 | 비동기 처리                        |
|----------|-------------------------|---------------------------------|
| CPU 활용률 | 낮음(대기 시간 발생)         | 높음 (대기 시간 최소화)              |
| 응답 시간   | 느림                     | 빠름                             |
| 구현 난이도 | 쉬움                      | 상대적으로 복잡(콜백/스레드 관리 필요)   |
| 적합한 환경 | 단순 요청, 처리량이 적은 시스템 | 대규모 트래픽, 외부 API 호출, I/O 작업 |

### 스레드 기반 비동기 처리
- Thread를 이용한 비동기 처리
  - Thraed 클래스를 사용
  - 직접 스레드를 생성하지 않고, 스레드 풀을 사용
 
- ExecutorService를 이용한 스레드 풀 관리
  - **스레드 풀**
    - 미리 생성해둔 일정 수의 스레드를 재활용하는 구조
    - 매번 스레드를 새로 생성하지 않아도 되므로, 자원을 절약하고 안정적인 성능을 유지할 수 있음
  - 스레드 생성, 관리, 종료를 자동으로 처리 함
 
- CompletableFuture를 이용한 고수준 비동기 처리
  - 콜백 기반으로 비동기 작업 연결
  - 콜백을 이용해 논블로킹 체이닝 가능
  - 에러 핸들링 지원
  - 여러 비동기 작업을 합성 가능

- CPU 작업과 I/O 작업을 분리하여 다른 스레드 풀을 사용하는 것이 좋음

### 이벤트 루프 기반 비동기
- 이벤트 루프는 단일 스레드 환경에서도 수천 개의 요청을 효율적으로 처리할 수 있는 비동기 모델
- 주로 I/O 중심 애플리케이션(네트워크, 파일, DB 요청 등)에서 매우 효과적
- 대표적으로 Node.js, Spring WebFlux, Project Reactor 등이 이 모델을 사용

#### 이벤트 루프 구성 요소
- 이벤트 루프 : 요청의 등록, 실행, 완료를 관리하는 메인 루프 스레드
- 이벤트 큐 : 처리해야 할 요청(작업)을 저장하는 큐
- 콜백 : 작업 완료 후 실행될 코드 블록
- Non-Blocking I/O API : OS 수준에서 제공되는 비동기 처리 기능

#### 이벤트 루프 장점과 한계
- 장점 :
  - 스레드 생성/관리 오버헤드 없음
  - 메모리 효율 높음
  - 동시 요청 처리량 우수
 
- 한계 :
  - CPU 연산이 많은 작업에는 부적합
  - 콜백 중첩 발생 가능
 
### 메시지 기반 비동기 처리
- 서로 다른 시스템이나 프로세스 간에 메시지를 교환하며 비동기적으로 작업을 처리하는 방식
- 메시지 큐가 중간에서 데이터를 안전하게 전달하고 일시적으로 보관

- 메시지 큐의 구조와 동작
  - 메시지 큐는 요청과 응답이 동시에 처리되지 않아도 되는 비동기 구조를 제공
  - 발신자는 메시지를 보낸 뒤 기다릴 필요 없이 바로 다음 작업을 수행할 수 있으며, 수신자는 나중에 메시지를 꺼내 처리
 
- 구성 요소
  - Producer : 메시지를 생성하여 큐로 전송 / 발신 후 대기하지 않음
  - Message Queue : 메시지를 임시 저장하고 전달 보장 / 네트워크 지연이나 서버 다운에도 안정적
  - Consumer : 큐에 쌓인 메시지를 순서대로 소비 / 병렬로 여러 Consumer를 둘 수 있음
 
- 메시지 큐의 특징
  - 비동기성 : 요청과 응답이 동시에 일어나지 않아도 됨
  - 내결함성 : Consumer 장애 시에도 메시지가 손실되지 않음
  - 확장성 : 여러 Consumer가 병럴로 메시지를 처리 가능
  - 순서 보장 : FIFO 기반으로 메시지 순서 유지 가능
  - 버퍼링 : 과도한 요청 폭주 시 임시 저장소 역할 수행
 
### 발행 구독 패턴
- 하나의 메시지를 여러 구독자에게 동시에 전달할 수 있는 구조
- 생산자는 단 한 번 메시지를 발행하지만, 이를 구독한 모든 소비자가 동일하게 받을 수 있음

#### 기존 메시지 큐 , pub-sub 패턴 비교
| 항목 | 메시지 큐 | 발행-구독 |
|-|-|-|
| 메시지 전달 대상 | 한 Consumer만 수신 | 여러 Subscriber에게 전달 가능 |
| 사용 예시 | 주문 처리, 이메일 발송 등 | 실시간 알림, 스트리밍, 브로드캐스트 |
| 데이터 보존 | 처리 후 삭제 됨 | 일정 기간 Topic에 저장 가능 |
| 메시지 분류 | 큐 단위 | 토픽 단위 |
| 시스템 구조 | Point-to-Point | Broadcast(Fan-out) |

#### 적용
- 서비스 유형
  - 실시간 알림
  - 이벤트 로깅
  - 주문 시스템
  - 스트리밍 데이터
 
### 비동기 처리가 필요한 경우
- 동기 방식의 한계
  - I/O 요청이 끝나기 전까지 서버 스레드는 블로킹 상태
  - 대량 요청이 들어오면 스레드 수 증가 -> 메모리/CPU 낭비 -> 처리 지연
 
- 비동기 방식의 이점
  - 비동기는 요청을 보내고 응답을 기다리지 않은 채 다음 작업을 처리
  - 요청 수만큼 스레드가 필요 -> 스레드는 생성/관리 비용이 커서, 일정 수준을 넘으면 스레드 컨텍스트 스위칭 비용이 폭증
  - 스레드 수를 늘리지 않아도 대기 중인 요청을 교차 처리 -> CPU는 항상 일하는 상태를 유지하여 처리량이 증가
 
### 스레드
- 스레드는 프로그램 내에서 독립적으로 실행되는 흐름을 의미
- 하나의 프로그램(프로세스) 안에서 여러 스레드가 동시에 작업을 수행할 수 있음
- 각 스레드는 메모리를 공유하며, 병렬적으로 작업을 수행할 수 있음

- 프로세스와 스레드
| 항목 | 프로세스 | 스레드 |
|-|-|-|
| 실행 단위 | 프로글매 전체 실행 | 프로그램 내 일부 실행 흐름 |
| 메모리 공간 | 독립적 메모리 영역 | 프로세스 내 메모리 공유 |
| 통신 방식 | IPC(Inter Process Communication) 필요 | 메모리 공유로 빠름 |
| 생성 비용 | 높음 (OS에서 자원 할당 필요) | 낮음 (프로세스 내 생성) |
| 예시 | 크롬 브라우저, IntelliJ, Discord | 탭별 실행, UI/네트워크 처리 스레드 |

- 메인 스레드
  - 가장 먼저 실행되는 메서드는 main 메서드
  - 메인 스레드가 main 메서드를 실행시켜 줌
  - 메인 스레드는 main 메서드의 코드를 처음부터 끝까지 차례대로 실행시키며, 코드의 끝을 만나거나 return문을 만나면 실행 종료
  - 자바 프로그램이 실행될 때 자동으로 생성되는 스레드이며, 프로그램의 시작점이 됨
 
- 작업 스레드
  - 하나의 프로세스는 여러 개의 스레드를 가질 수 있으며, 이를 멀티 스레드 프로세스라 함
  - 여러 개의 스레드를 가진다는 것은 여러 스레드가 동시에 작업을 수행할 수 잇음을 의미 -> 멀티 스레딩
  - 작업 스레드는 백그라운드나 별도의 계산, 네트워크 통신, 파일 입출력 등을 처리하기 위해 사용
 
- 멀티스레드의 장점과 위험성
  - 장점 :
    - CPU의 멀티코어를 효율적으로 활용할 수 있음
    - 동시에 여러 작업을 수행할 수 잇음
    - 사용자 경험을 개선할 수 있음
   
  - 위험성 :
    - 자원을 동시에 접근할 경우 경쟁 상태가 발생할 수 있음
    - 잘못된 동기화로 인해 데드락이 발생할 수 있음
    - 디버깅과 테스트가 어려워 짐
   
### 스레드 생성과 실행
- 작업 스레드가 수행할 코드를 작성하고, 작업 스레드를 생성하여 실행시키는 것을 의미
- run()이라는 메서드 내에 스레드가 처리할 작업을 작성해야 함
  - run() 메서드는 Runnable 인터페이스와 Thread 클래스에 정의되어 있음
  - 1. Runnable 인터페이스를 구현한 객체에서 run()을 구현하여 스레드를 생성하고 실행하는 방법
    2. Thread 클래스를 상속받은 하위 클래스에서 run()을 구현하여 스레드를 생성하고 실행하는 방법
  - run()은 단순히 작업 내용만 정의하며, start()를 호출해야 JVM이 새로운 스레드를 생성하여 병렬로 실행
 
- Runnable 인터페이스
  - 스레드를 정의하기 위한 함수형 인터페이스
 
- Thread 클래스
  - 자바에서 스레드를 직접 표현하는 클래스
 
#### Thread 실행 제어
- start()
  - 스레드를 실행하려면 반드시 start() 메서드를 호출해야 함
- sleep()
  - 현재 실행 중인 스레드를 일정 시간 동안 멈추게 함
- join()
  - 특정 스레드가 끝날 때까지 다른 스레드를 대기 시킴
- interrupt()
  - 스레드를 강제 종료하지 않고, 단지 중단 요청 신호를 보냄
  - 스레드 내부에서 isInterrupted()나 InterruptedException을 통해 이를 감지하고 직접 종료를 제어
 
### 멀티 스레드 위험성
- 멀티스레드는 동시에 여러 작업을 처리할 수 있지만, 공유 자원을 동시에 접근할 때 심각한 문제가 발생할 수 잇음
- 이러한 문제는 대부분 Race Condition (경쟁 상태)에서 비롯됨
- 작업이 원자적으로 수행되지 않으면 발생 -> 읽기와 쓰기가 분리되어 수행되는 비원자적 연산에서 자주 발생

### 동기화 방법
- 여러 스레드가 동시에 동일한 객체나 변수에 접근할 수 있음 -> Race Condition이 발생하여 데이터가 손상될 수 있음
- 이를 방지하기 위해 동기화를 적용
- 동기화란 여러 스레드가 하나의 공유 자원을 동시에 접근하지 못하도록 임계 구역을 설정하는 방법
- 한 스레드가 자원을 점유하면 다른 스레드는 대기 상태로 전환되어 순차적으로 접근

#### 임계 영역과 락
- 임계 영역은 오로지 하나의 스레드만 코드를 실행할 수 있는 코드 영역을 의미
- 락은 임계 영역을 포함하고 있는 객체에 접근할 수 있는 권한을 의미
- 특정 코드 구간을 임계 영역을 설정할 때는 synchronized라는 키워드를 사용

#### 스레드 안전 컬렉션의 필요성
- 멀티스레드 환경에서는 여러 스레드가 동시에 같은 컬렉션 객체에 접근할 수 있음
- ex: ArrayList에 여러 스레드가 동시에 add() 작업을 수행하면 내부 배열 인덱스가 꼬여서 IndexOutOfBoundsException이 발생할 수 있음

- ConcurrentHashMap
  - HashMap을 개선하여, 여러 스레드가 동시에 데이터를 읽고 쓰더라도 안전하게 동작하도록 설계된 구조
  - 내부적으로 데이터를 여러 개의 구역으로 분하랗여 관리
  - 각 구역은 별도의 락을 가지고 있어서, 여러 스레드가 동시에 서로 다른 구역을 수정할 수 있음
  - 덕분에 성능과 스레드 안전성을 모두 보장
 
- BlockingQueue
  - 스레드 간 데이터 교환을 위해 설계된 큐 구조
  - put()은 큐가 가득 차면 대기하고, take()는 큐가 비어 있으면 대기
  - 주요 구현체
    - ArrayBlockingQueue
    - LinkedBlockingQueue
    - PriorityBlockingQueue
    - DelayQueue
   
### 스레드 풀
- 스레드 풀은 미리 생성해둔 스레드 집합에서 작업을 가져와 실행하는 방식
- 매번 새로운 스레드를 만들지 않고 이미 만들어진 스레드를 재사용함으로써 성능을 향상 시킴

- 필요성
  - 스레드 생성/소멸 비용 절감
    - 스레드는 생성할 때마다 메모리 스택 공간과 운영체제의 문맥 등록이 필요
    - 매 요청마다 새 스레드를 생성하면 성능이 급격히 저하됨
    - 스레드 풀은 이러한 문제를 해결하기 위해 스레드를 미리 만들어 재사용
   
  - 스레드 개수 제한을 통한 자원 관리
    - 시스템은 한정된 CPU 코어와 메모리를 가지고 있으므로, 스레드가 많을수록 문맥 전환 비용이 커짐
    - 최대 스레드 개수를 제한하여 시스템 자원을 보호
    - 이렇게 하면 CPU가 처리 가능한 양을 초과하는 스레드가 생기지 않아 안정적인 실행이 가능
   
- 작업 큐
  - 스레드 풀에서 작업 요청은 먼저 작업 큐에 저장됨
  - 스레드가 비면 큐에서 하나씩 작업을 꺼내 실행함
 
- 단일 스레드는 모든 작업이 순차적으로 실행되므로 처리 속도가 매우 느림

### Executor
- 스레드를 직접 생성하고 관리하는 복잡성을 줄이기 위해 추상화한 인터페이스 Executor 제공
- ExecutorService 같은 구현체를 활용
  - why?
    - 스레드 생성 비용 문제
    - 자원 관리의 어려움
    - 비동기 결과 및 예외 처리 부족

| 구분 | 단순 Executor 직접 구현 | ExecutorService 사용 |
|-|-|-|
| 스레드 생성 비용 | 매번 new Thread()로 생성 -> CPU/메모리 낭비 | 스레드 풀을 사용해 재사용 |
| 자원 관리 | 스레드 종료,예외 처리 직접 관리 필요 | shutdown(), awaitTermination() 등 관리 기능 제공 |
| 결과 처리 | 반환값 관리 불가능 (Runnable만 가능) | Callable, Future로 결과 추적 가능 |

- ExecutorService는 스레드의 생명주기 관리 기능이 추가된 구조
  - 스레드를 종료할 수 있고(shutdown)
  - 결과를 반환받을 수 있으며(Callable / Future)
  - 여러 작업을 동시에 제출하고 관리할 수 있음
 
- Runnable은 결과를 반환하지 않지만, Callable은 작업이 끝난 뒤 결과를 반환할 수 있음
  - 이때 반환값을 비동기적으로 받을 수 있는 객체가 바로 Future
 
- ScheduledExecutorService
  - 작업을 일정 주기로 예약할 수 있음

### 스레드 풀 예외 처리
- Future를 통한 예외 처리
  ```java
  future.get(); // 예외를 던짐 try-catch로 예외 처리
  ```
  - 내부에서 발생한 예외는 ExecutionException으로 감싸져 전달 됨

### Runnable의 한계
- 결과값을 반환할 수 없음
- 예외도 메인 스레드로 전달되지 않음
- 반환값 부재
- 예외처리 불가
- 비동기 제어 어려움

### Callable
- 반환값을 가지며, 예외를 던질 수 있음
- call()
- 단독으로 실행되지 않고 ExecutorService를 통해 실행 됨
- 제네릭을 사용하여 반환 타입을 명확하게 지정

### Future
- 비동기 작업의 결과를 나중에 받을 수 있게 해주는 인터페이스
- Callable이나 Runnable의 실행 결과를 나중에 조회하거나 제어할 수 있도록 함
- 주요 메서드
  - get() : 작업이 완료될 때까지 블로킹하여 결과를 반환
  - get(long timeout, TimeUnit unit) : 지정된 시간 동안만 대기하고, 초과 시 TimeoutException 발생
  - cancel(boolean myaInterruptIfRunning) : 작업을 취소함
  - isDone() : 작업이 완료되었는지 여부를 반환
  - isCancelled() : 작업이 취소되었는지 여부를 반환


### ExecutorService와 Future
- ExecutorService.submit() 비동기 작업을 스레드 풀에 제출하고, 즉시 Future 객체를 반환
  - 여러 개의 Callable을 리스트 형태로 만들어 제출하면, 각 작업마다 별도의 Future를 받을 수 있음
- invokeAll()
  - 모든 작업 완료 대기
  - 모든 작업이 끝날 때까지 기다림
  - 일괄처리에 유용
- invokeAny()
  - 가장 먼저 끝난 작업의 결과만 받기
  - 여러 작업 중 가장 빨리 끝난 하나의 결과만 반환
  - 나머지 작업은 자동으로 취소
  - 빠른 응답이 필요한 서비스(여러 서버 중 가장 빨리 응답한 결과 사용)에 적합

### Future 한계
- get() 메서드는 결과가 준비될 때까지 현재 스레드를 멈추게 함
- 이로 인해 비동기 실행의 장점이 반감되는 문제가 발생할 수 있음
- 블로킹의 실질적 문제
  - CPU 낭비
  - 응답 지연
  - 확장성 저하
 
- 콜백 메커니즘의 부재
  - Future는 단순히 결과를 보관하는 객체이므로, 작업이 완료되었을 때 자동으로 후속 동작(콜백)을 실행할 수 없음
 
- 연쇄 작업의 어려움
  - Future는 반환값을 직접 받아서 다음 작업에 넘기는 방식 외에는 연결 실행이 불가능
  - 각 단계가 끝날 때마다 직접 get()으로 결과를 확인해야 함
 
### CompletableFuture
- 기존 Future의 문제
  - 블로킹 문제
  - 콜백 부재
  - 연쇄 작업 불가
  - 비동기 처럼 보이지만 실질적으로는 동기에 가까운 구조

- 비동기 단계를 연결할 수 있는 구조 제공
  - 비동기 작업을 조합하고 연결할 수 있는 실행 파이프라인

- 람다 표현식과 메서드 체이닝을 결합하여 비동기 코드를 마치 데이터 스트림처럼 자연스럽게 표현할 수 잇음

#### CompletionStage
- 여러 비동기 작업을 단계로 표현하고, 이들을 연결할 수 있도록 설계된 인터페이스
- 즉 작업이 끝나면 다음 작업을 실행하라는 개념을 코드 수준에서 지원

- 핵심 메서드 분류
  - 결과 변환 thenApply() : 이전 결과를 변환하여 반환
  - 결과 소비 thenAccept() : 결과를 받아 처리하고 반환 없음
  - 후속 실행 thenRun() : 결과와 관계없이 후속 동작 수행
  - 조합 실행 thenCombine(), thenCompose() : 여러 작업 결합 및 순차 연결

- 핵심 장점 요약
  - 비동기 자동 연결 CompletionStage 기반의 체이닝 지원
  - 함수형 구성 : 람다와 체이닝으로 간결한 코드 작성 가능
  - 콜백 내장 : 작업 완료 후 자동 후속 처리 지원
  - 병렬 처리 지원 : 여러 비동기 작업을 결합하여 병렬 수행 가능
  - 명시적 예외 처리 : handle(), exceptionally() 등 예외 흐름 관리 가능
 
### CompletableFuture 생성 방식
| 메서드 | 반환 타입 | 설명 |
|-|-|-|
| runAsync(Runnable) | CompletableFuture<Void> | 반환값이 없는 비동기 작업 실행 |
| supplyAsync(Supplier<T>) | CompletableFuture<T> | 반환값이 있는 비동기 작업 실행 |
| completedFuture(T value) | CompletableFuture<T> | 이미 완료된 Future를 생성 |

- CompletableFuture.join()
  - 비동기 작업이 끝날 때까지 현재 스레드를 대기(Blocking)시킴
  - 작업이 끝나면 결과를 반환하거나, 예외가 발생했을 경우 RuntimeException으로 래피앟여 던짐
  - 즉, 결과를 기다리되 Checked Exception을 던지지 않기 때문에 테스트 코드나 간단한 데모 코드에서 매우 자주 사용 됨.
 
- join(), get()
| 구분 | get() | join() |
|-|-|-|
| 예외 처리 | InterruptedException, ExecutionException(checked) | CompletionException(Unchecked) |
| 코드 작성 난이도 | 예외 처리 필요(try-catch 필수) | 예외 처리 선택적 (try-catch 없어도 됨) |
| 사용 용도 | 실무 서비스 코드 | 테스트, 간단한 예제 |
| 반환 시점 | Future 완료 시까지 대기 | Future 완료 시까지 대기 |
| 예외 래핑 | ExecutionException | CompletionException |

#### ForkJoinPool.commonPool()
- 자바가 기본적으로 제공하는 공용 스레드 풀
- supplyAsync()를 실행할 때 별도의 Executor를 지정하지 않으면 자동으로 이 공용 풀에서 스레드가 할당되어 작업을 수행하게 됨

### 기본 작업 처리 메서드
| 메서드 | 인자 타입 | 반환 타입 | 설명 |
|-|-|-|-|
| thenApply() | Function<T,R> | CompletableFuture<R> | 결과값을 변환하여 다음 단계로 전달 |
| thenAccept() | Consumer<T> | CompletableFuture<Void> | 결과값을 소비(출력, 저장 등)하고 반환값 없음 |
| thenRun() | Runnable | CompletableFuture<Void> | 이전 결과를 사용하지 않고 새로운 작업 실행 |

- thenApply
  - 이전 작업의 결과를 입력으로 받아 새로운 결과를 생성
 
- thenAccept()
  - 이전 작업의 결과를 단순히 소비 하며, 새로운 결과를 반환하지 않음
 
- thenRun()
  - 이전 작업의 결과를 전혀 사용하지 않고, 새로운 독립 작업을 실행
 
- get() : 블로킹 : checked 예외 처리 : 즉시 반환 X
  - 표준 Future 방식으로 결과 대기

- join() : 블로킹 : Unchecked 예외 처리 : 즉시 반환 X
  - 예외 처리가 간단한 대체 메서드
 
- getNow(defaultValue) : 비블로킹 : 예외 처리 없음 : 즉시 반환 O
  - 완료되지 않았으면 기본값 반환
 
### 비동기 작업 조합의 필요성
- CompletableFuture 단일 작업만 처리하는 것이 아니라, 여러 비동기 작업을 연결하거나 결합할 수 있음
- 이때 사용하는 핵심 메서드가 바로 thenCompose(), thenCombine(), allOf(), anyOf()

| 메서드 | 개념 요약 | 동작 형태 |
|-|-|-|
| thenCompose() | 순차 실행 | 결과 -> 다음 작업 입력 |
| thenCombine() | 병렬 실행 후 결합 | 두 Future 결과 결합 |
| allOf() | 다수 작업 모두 완료 시 | 전체 완료 대기 |
| anyOf() | 다수 작업 중 하나 완료 시 | 첫 완료 즉시 반환 |

- thenCompose
  - 이전 비동기 결과를 받아 다음 비동기 작업으로 연결할 때 사용
  - 내부적으로 Future의 중첩 구조를 평탄화
 
- thenCombine
  - 두 개의 독립적인 비동기 작업을 병렬로 실행하고,
  - 두 결과를 결합하여 새로운 결과를 생성
  - AFuture.thenCombine(BFuture, (A,B) -> {})
    - 서로 독립적인 두 Future를 병렬로 수행한 뒤, 두 결과를 하나의 결과로 합치는데 사용
   
- allOf()
  - 여러 비동기 작업이 모두 완료될 때 가지 기다림
  - 반환형이 CompletableFuture<Void>
  - 모든 작업이 끝났다는 신호만 알려줄 뿐, 각 작업의 결과값은 직접 반환하지 않음
    - 이후 .join()으로 각각의 결과를 꺼내야 함
   
- anyOf()
  - 여러 비동기 작업 중 가장 먼저 완료된 결과를 반환
  - 첫 번째로 끝난 결과만 필요할 때 유용
  - ex: 여러 서버 중 가장 빠른 응답을 사용하는 경우
 
### 비동기 예외 처리
- 비동기 프로그램에서는 스레드 내부에서 예외가 발생해도 실시간에 외부로 전달되지 않음
- 이때부터 단순한 try-catch 문으로는 예외를 포착할 수 없음
- Completion이라는 새로운 예외로 감싸져 던져짐
- get() -> ExecutionException
- join() -> CompletionException

- exceptionally()
  - 예외가 발생했을 때만 호출되는 복구 콜백
  - 정상적으로 완료되면 무시, 오류 건은 따로 처리
 
- handle()
  - 성공과 실패를 모두 처리할 수 있는 콜백
  - 첫번째 매개변수 : 정상 결과값 (예외 시 null)
  - 두번째 매개변수 : 예외 객체 (정상 시 Null)

- whenComplete()
  - 결과를 변경하지 않고, 후처리(로깅, 리소스 정리 등)에 사용 됨
  - 결과는 그대로 다음 단계로 전달 됨
 
### 타임아웃
- 비동기 프로그램에서는 외부 서비스 지연, 네트워크 문제, 무한 대기 상태와 같은 상황이 빈번하게 발생
  - 이때 타임아웃을 설정하지 않으면, 프로그램은 결과를 무한히 기다리게 되어 시스템 전체의 응답성이 저하 됨
 
- 핵심 목적
  - 외부 의존성의 지연으로부터 시스템 보호
  - 사용자의 응답 대기 시간 제한
  - 장애 허용 전략 구현
  - 복구 로직 트리거 역할 수행
 
- orTimeout()
  - 지정한 시간이 지나도 Future가 완료외지 않으면 예외를 발생시킴
  - java.tuil.concurrent.TimeoutException 형태로 발생
    - 내부적으로 completeExceptionally()가 호출 됨
   
- completeOnTimeout()
  - 지정한 시간이 지나도 완료되지 않으면 예외 대신 기본값을 반환
  - 타임아웃 발생 시 예외를 던지지 않음
  - 기본값으로 Future를 정상 완료시킴
  - 안정성이 요구되는 서비스(Fallback 처리)에 적합함
 
### Spring 비동기 처리의 필요성
- 요청량 폭증과 응답 속도 저하가 비넙ㄴ히 발생
  - spring의 비동기 처리 기능은 성능 개선과 사용자 경험 향상을 동시에 달성하는 핵심 기술
 
- 대용량 트래픽 환경에서의 성능 개선
  - 비동기로 해결
 
- 사용자 경험 향상을 위한 응답 시간 최적화
  - 3초 기다리는 대신, 즉시 "요청이 접수되었습니다"라는 메시지를 받는다면 훨씬 만족도가 높아짐
  - 비동기 처리를 통해 서버는 "응답"과 "처리"를 분리하여 사용자에게 즉시 피드백을 제공
  - 비동기 처리는 "빠른 응답 + 백그라운드 처리"로 UX와 성능을 동시에 개선

### Spring 비동기 처리 방식 소개
- Spring은 @Async 어노테이션을 기반으로 한 고수준 비동기 처리 메커니즘을 제공
- 스레드 관리, 예외 처리, 트랜잭션 분리를 자동으로 지원
- Spring에서 비동기 처리를 활성화하면, 내부적으로 프록시 객체가 생성되어 비동기 메서드를 별도의 스레드에서 실행
- 핵심 구성요소
  - @Async : 메서드를 비동기로 실행하도록 표시
  - @EnableAsync : 비동기 기능 활성화(프록시 생성)
  - TaskExecutor : 비동기 스레드를 관리하는 실행기
  - ThreadPoolTaskExecutor : 실무에서 가장 많이 사용하는 스레드풀 구현체
  - AsyncUncaughtExceptionHandler : 비동기 메서드의 예외 처리 담당
 
- @EnableAsync
  - 비동기 기능을 사용하려면 먼저 @EnableAsync를 통해 Spring 컨테이너에 비동기 기능을 등록해야 함
  - 내부적으로 AsyncAnnotationBeanPostProcessor를 등록하여, @Async가 붙은 메서드를 프록시로 감싸고 비동기 스레드 풀에 위임할 수 있게 만듦

### @Async 어노테이션 활용
- 비동기 처리를 선언적으로 구현
- @EnableAsync가 활성화된 상태에서 @Async가 붙은 메서드는 별도의 스레드에서 실행
- @Async는 내부적으로 AOP 기반 프록시를 활용
  - 비동기 메서드를 호출할 때 프록시가 가로채서 해당 메서드를 TaskExecutor 스레드풀에 위임

- 지원 반환 타입
  - void : 단순 비동기 실행, 결과가 필요없는 경우
  - Future<?> 또는 ListenableFuture<?> : 비동기 결과를 나중에 조회 가능
  - CompletableFuture<?> : 비동기 완료 후 후속 작업 수행 가능

### @Async 제약 사항
- 프록시 기반 동작의 이해
  - @Async는 AOP 기술을 활용하여 프록시 객체를 통해 동작
  - 비동기 메서드가 호출될 때, 실제 대상 객체가 아닌 프록시 객체가 메서드 실행을 가로채어 비동기로 위임
- 자가 호출(Self-Invocation) 문제
  - @Async는 같은 클래스 내부에서 메서드를 호출할 경우 동작하지 않음
  - 직접 호출할 경우, 프록시를 거치치 않아 동기 실행 됨

- 해결 방법
  - 프록시 Bean을 통해 호출하기
  - @Async 메서드를 별로 Bean으로 분리
  - 접근 제한자 제약
    - @Async는 public메서드에만 적용 됨.
    - Spring의 프록시가 public 메서드 호출만 가로챔
  - 트랜잭션 전파 이슈
    - @Transactional과 @Async는 서로 다른 스레드 컨텍스트에서 동작
    - 기존 트랜재션을 상속받지 않음
- 비동기 트랜잭션 문제 해결 방법
  - 비동기 실행 시점을 제어하거나 트랜잭션 컨텍스트를 명시적으로 전달해야 함
  - 비동기 호출을 트랜잭션 외부로 이동
    - 가장 단순하고 안전한 방법은 트랜잭션이 완전히 커밋된 이후 시점에 비동기 메서드를 호출하도록 구조를 바꾸는 것
    - 트랜잭션 내 로직과 비동기 처리를 명확히 분리하여 트랜잭션 상태에 의존하지 않는 안정적인 비동기 처리 구조를 제공
  - @TranscationalEventListener
    - 트랜잭션 종료 시점을 감지할 수 있는 이벤트 리스터를 제공
    - 이를 이용하면 트랜잭션 커밋 후 비동기 작업을 실행할 수 있음
    - @TransactionalEventListener(phase=AFTER_COMMIT)를 사용하면 트랜잭션이 완료된 후 비동기 로직이 안전하게 실행 됨
      - 트랜잭션이 롤백되면 이벤트 자체가 실행되지 않음
    - 트랜잭션 컨텍스트를 명시적으로 전달
      - TransactionSynchronizationManager를 이용해 트랜잭션 속성을 직접 복사해 전달할 수 있음
      - 실무에서는 대신 이벤트 기반 처리 방식을 더 선호

### TaskExecutor
- Spring TaskExecutor는 Java의 Executor 인터페이스를 확장하여, 스레드 실행을 좀 더 유연하고 관리하기 쉽게 만들어 줌
- Spring은 프레임워크 전반의 일관성과 빈 기반의 설정/주입/관찰을 위해 TaskExecutor 추상화를 제공
  - 프레임워크 표준화 : 스케줄러, 이벤트, @Async 등 여러 모듈이 같은 실행 추상화를 사용
  - 빈 기반 구성 : YAML/Java Config로 환경별 다른 실행 전략을 쉽게 교체
  - 운영 가시성 : 스레드 이름 프리픽스, 메트릭 노출, 거부(포화) 저책 등 운영 친화 옵션과의 결합이 쉬움
  - 일관된 예외 처리 관점 : @Async와 결합 시 비동기 예외 처리 진입점(AsyncUncaughtExceptionHandler)이 명확해짐
- CPU 연산 작업과 I/O 중심 작업을 같은 스레드 풀에서 처리하면 병목이 발생할 수 있음
  - 여러 TaskExecutor를 정의해 자원을 분리하는 것이 좋음
 
### 스레드 풀 포화 감지 및 대응 전략
- 스레드 풀이 감당할 수 있는 최대 스레드 수와 큐 용량을 초과하면, 더 이상 새로운 작업을 수용할 수 없는 상태를 의미
- 이때는 RejectedExceptionHandler가 동작하여, 정책에 따라 작업을 거부하거나 다른 방식으로 처리
- 징후
  - 작업 처리 속도가 점점 느려짐
  - 응답 지연이 급격히 증가
  - CPU 사용률은 낮지만, 큐가 계속 증가
- 스레드 풀의 포화 상태를 감지하여 알림을 보내기도 함

### Spring Event
- Spring의 이벤트 시스템은 애플리케이션 내부에서 비동기적으로 로직을 분리하고 결합도를 낮추기 위한 구조 제공
- 구조
  - ApplicationEvent 이벤트 객체 : 발생한 사건(이벤트)의 정보를 담는 객체
  - ApplicationEventPublisher 이벤트 발행자 : 특정 시점에 이벤트를 발생시키는 역할
  - ApplicationListener 이벤트 수신자 : 발행된 이벤트를 감지하고, 후속 동작 수행

#### 이벤트 기반 아키텍처의 장점
- 결합도 감소와 유지보수성 향상
- 확장성과 유연성
- 비동기 확장 기반

#### @EventListener
- 하나의 클래스에서 여러 이벤트 처리 가능
- condition 속성을 사용하여 특정 조건일 때만 이벤트를 처리할 수 있음
  - 이벤트의 필드 값을 검사해 필터링된 이벤트 처리가 가능
 
#### 비동기 이벤트 처리
- Spring Event 시스템은 기본적으로 동기 방식으로 동작
- 오래 걸리는 작업은 비동기로 처리하는 것이 효율적
- @EventListener와 @Async 조합
- @TransactionalEventListener
  - 트랜잭션의 상태에 따라 이벤트를 처리할 수 있게 해줌
  - 데이터베이스 트랜잭션이 완료된 시점에 맞춰 이벤트를 실행할 수 있음

#### 이벤트 기반 비동기 처리
- 핵심 로직과 부가 로직을 분리하는 데 초점
- 부가 로직을 이벤트 리스너로 분리하고 비동기로 실행하면, 시스템은 더욱 빠르고 유연하며 유지보수가 쉬워짐

#### 분산환경 이벤트
- Spring Event는 ApplicationContext 내부에서만 작동.
  - 분산 환경에서 처리하기 어려움
 
- 메시지 브로커
  - 이 문제를 해결하기 위해 등장
  - 여러 애플리케이션 간에 메시지(이벤트)를 중간에서 안전하게 전달해주는 시스템
  - 역할
    - Producer : 메시지를 발행하는 주체 (Publisher 역할)
    - Broker : 메시지를 임시 저장 및 관리하는 서버
    - Topic/Queue : 메시지를 구분하기 위한 논리적 공간
    - Consumer : 메시지를 구독하여 처리하는 주체
   
- Kafka
  - 고성능 메시지 스트리밍 플랫폼
  - 이벤트를 중앙 Topic에 저장하고 다수의 소비자가 이를 병렬로 처리
  - Domain 이벤트
    - 하나의 서비스 내부에서 발생하는 비즈니스 상태 변화를 표현
    - 이벤트를 통해 내부 모듈 간 결합도를 낮춤
    - @EventListener 기반으로 비동기 처리할 수 있음
   
  - 통합 이벤트
    - 서비스 간 데이터 교환을 위한 이벤트
    - 다른 애플리케이션이 구독할 수 있도록 외부 브로커에 발행
   
### 비동기 처리의 예외 처리
- 비동기 메서드는 새로운 스레드에서 실행됨.
- 메인 스레드에서 발생하는 예외 전파 규칙이 그대로 적용되지 않음
- 각 스레드는 독립적잉ㄴ 호출 스택을 가지고 있으며, 비동기로 실해오디는 메서드는 완전히 다른 스레드의 스택 공간에서 동작.
  - 따라서 한 쪽 스레드의 예외는 다른 쪽으로 전파 되지 않음.
 
- @Async 메서드는 내부적으로 ExecutorService.submit(Callable) 형태로 실행 됨
- 반환 타입이 void이면 Future 객체가 만들어지지 않으므로 예외나 결과를 확인할 수 없음
  - 따라서 비동기 결과 추적이 필요한 경우 반드시 Future나 CompletableFuture를 반환해야 함.
  - 예외 처리를 위한 주요 접근 방식
    - AsyncUncaughtExceptionHandler : void 메서드의 예외를 글로벌하게 처리
    - Future/CompletableFuture : 비동기 결과를 반환받아 예외를 직접 확인
    - 로깅/모니터링 시스템 : 예외 로그를 중앙화 시스템에 전달
   
#### 비동기 메서드의 반환 타입별 예외 전파 구조
- 반환 타입 void : 호출자에게 전파되지 않음
  - AsyncUncaughtExceptionHandler 필요
- Future<T> : get() 호출 시 예외 확인 가능
  - ExecutionException 내부로 래핑되어 전달
- CompletableFuture<T> : 체이닝 내에서 직접 처리 가능
  - exceptionally(), handle() 메서드 사용
 
#### AsyncUncaughtExceptionHandler
- 비동기 메서드는 호출 스레드와 별개로 실행되므로, 예외가 발생해도 호출자에게 전파되지 않음
  - 이때 비동기 스레드 내부에서 발생한 예외를 감지하고 로깅하기 위해 사용하는 것이 AsyncUncaughtExceptionHandler
- @Async로 실행된 void 반환 메서드의 예외를 감지하기 위한 전용 인터페이스
- 비동기 스레드에서 예외가 발생하면, 스프링이 handleUncaughtException 을 자동으로 호출함.

#### 비동기 예외처리 모범
- 재시도 메커니즘
  - 재시도는 일시적인 네트워크 오류나 타임아웃 등의 문제로 작업이 실패했을 때, 동일 작업을 일정 횟수 다시 시도하는 전략
  - 이 전략은 일시적인 장애를 복구하는 데 효과적
 
- 폴백 전략
  - 특정 작업이 실패했을 때 대체 동작을 수행하여 시스템의 가용성을 유지하는 방법
  - 외부 이메일 서버가 작동하지 않을 때 임시 메시지 큐에 저장하거나 관리자에게 알림을 전송할 수 있음
 
- 회로차단기 패턴
  - 외부 시스템에 지속적으로 실패 요청이 발생할 경우, 일정 시간 동안 호출을 중단하여 시스템을 보호하는 패턴
  - Closed : 정상 상태, 모든 요청 허용
  - Open : 오류율이 일정 임계치 초과 -> 호출 차단
  - Half-Open : 일부 요청 허용 -> 성공 시 복구, 실패 시 다시 차단

### TaskDecorator
- 비동기 작업은 별도의 스레드에서 실행되므로, 기존 요청 스레드의 ThreadLocal 변수가 그대로 전달되지 않음
  - 이로 인해 보안 컨텍스트, 트랜잭션 정보, 로깅 컨텍스트(MDC) 등이 손실되는 문제가 발생할 수 있음
 
- ThreadLocal
  - 각 스레드마다 독립적인 데이터를 저장할 수 있도록 도와주는 클래스
  - 여러 스레드가 동시에 하나의 객체를 공유하더라도, ThreadLocal을 사용하면 각 스레드는 자신만의 복사본을 가지게 됨
  - 스레드마다 별도의 저장소를 가지므로 동시성 문제를 방지할 수 있음
  - 하지만 새로운 스레드가 생성되면 기존 스레드의 ThreadLocal 데이터는 자동으로 복사되지 않음
 
- 발생하는 문제
  - 로그 추적 불가
    - 요청 스레드에서 MDC에 데이터를 넣더라도, 비동기 스레드로 넘어가면 복사되지 않음
  - 보안 컨텍스트 손실
    - 인증 사용자 정보가 비동기 스레드에 없음
  - 트랜잭션 단절

- TaskDecorator
  - 비동기 작업이 실행되기 직전에 스레드 컨텍스트를 복사하여 새로운 스레드에도 동일한 환경을 적용할 수 있도록 해주는 장치
  - 스프링에서 제공하는 함수형 인터페이스로 비동기 작업이 실행되기 전에 실행 환경을 래핑하여 커스터마이징할 수 있도록 설계되어 있음

#### 실행 컨텍스트 전달
- 비동기 환경에서는 스레드 풀에 의해 새로운 스레드가 재사용되기 때문에, 현재 스레드의 컨텍스트 정보가 새 스레드에 자동으로 전달되지 않음.
- TaskDecorator는 Runnable을 감싸서 컨텍스트를 복제하거나 초기화하는 역할을 함

- 두 개 이상의 데코레이터 적용
  - 스프링의 ThreadPoolTaskExecutor는 하나의 TaskDecorator만 설정할 수 있음
  - 따라서 동시에 전파하려면 두 데코레이터를 조합하는 별도의 CompositeTaskDecorator를 만들어야 함
  - 데코레이터 체인을 역순으로 감싸야 함 (가장 먼저 등록된 데코레이터가 가장 바깥쪽)
 
- 트랜잭션 컨텍스트 관리
  - 비동기 실행 시 스레드는 기존 트랜잭션 컨텍스트를 자동으로 상속받지 않음
  - 메인 스레드에서 트랜잭션이 시작되어도 비동기 스레드에서는 TransactionSynchronizationManager가 초기화되지 않아 새로운 트랜잭션처럼 동작하거나, 트랜잭션이 전혀 존재하지 않는 상태가 될 수 있음
  - 이러한 문제를 해결하기 위해, TaskDecorator에서 트랜잭션 컨텍스트를 복제하여 비동기 스레드에도 동일한 트랜잭션 환경을 설정할 수 있음
- TransactionalSynchronizationManager
  - 현재 스레드의 트랜잭션 관련 정보를 관리하는 스프링의 내부 유틸리티 클래스
  - 트랜잭션 매니저가 이 객체를 통해 리소스 바인딩, 트랜잭션 상태, 동기화 콜백 등을 관리

- 데코레이터 체인은 내부 -> 외부 순서로 감싸짐


### WebClient
- Spring WebFlux에서 제공하는 비동기-논블로킹 HTTP 클라이언트
- 기존 RestTemplate의 단점을 보완하여, Reactive Streams 기반의 비동기 처리 모델 제공

#### Reactive Streams 기본 개념
- WebClient는 Reactive Streams API(Publisher, Subscriber, Subscription) 기반 동작.
- Publisher : 데이터를 발행하는 쪽 (WebFlux)
- Subscriber : 데이터를 구독하고 처리하는 쪽 (응답 처리자)
- Subscription : Publisher <> Subscriber 간의 데이터 흐름 제어 (Backpressure)

#### WebClient 기본 구조
- builder패턴을 이용해 인스턴스를 재사용 가능한 형태로 구성

#### WebClient 응답 처리 기본 구조
- WebClient는 요청 전송 후 Mono<ClientResponse> 형태의 응답을 비동기로 반환
- retrieve(): 요청을 전송하고, 응답 상태 코드 검증 및 바디 추출 준비
- bodyToMono() / bodyToFlux() : 실제 응답 본문을 역질렬화

- 단일 객체 응답 (Mono)
- 컬렉션 응답 (Flux)

- 응답 처리 방식
| 구분 | retrieve() | exchangeToMono() |
|-|-|-|
| 반환 타입 | ResponseSpec | Mono<ClientResponse> |
| 목적 | 일반적인 응답 본문 처리 | 상태코드 / 헤더를 세밀하게 다뤄야 할 때 |
| 내부 처리 | 상태 코드 4xx/5xx 시 예외 발생 | 예외 발생 X(직접 처리 필요) |
| 사용 예시 | bodyToMono()/bodyToFlux()와 함께 | 로깅, 조건부 응답, 헤더 기반 처리 |

- 에러 핸들링
  - retrieve()는 4xx/5xx 응답 시 자동으로 예외를 발생
  - 이를 커스터마이징하려면 .onStatus()를 사용
  - onErrorResume()은 에러 발생 시 대체 데이터를 반환할 때 유용
  - onErrorMap()은 발생한 예외를 다른 예외로 변환할 때 사용
 
- 오류 복구
  - 타임아웃 설정
    - 타임아웃은 특정 시간 안에 응답이 없을 경우 요청을 강제로 종료하는 메커니즘
    - 타임아웃을 설정하지 않으면, 서버가 응답하지 않아도 요청이 계속 대기 상태로 남아 시스템 리소스를 낭비할 수 있음
   
  - 재시도 전략
    - 재시도는 일시적인 실패 시 동일 요청을 일정 횟수만큼 자동으로 재전송하는 기능
    - 재시도는 일시적 네트워크 오류에 유용하지만, 무한 반복 시 서버 과부하를 유발할 수 있음
   
  - 서킷 브레이커
    - 지속적인 실패를 감지하면 일시적으로 요청을 차단하여 시스템의 연쇄 장애를 방지하는 패턴
   
  - 동시 요청 처리
    - WebClient는 논블로킹 구조를 활용하여 여러 요청을 동시에 병렬 처리할 수 있음
   
### 비동기 처리 적용
- 비동기 처리는 응답 속도를 단축하거나 병렬로 여러 작업을 동시에 수행하기 위해 사용
- 비동기 처리의 부적합한 사용 사례
| 구분 | 설명 | 예시 |
|-|-|-|
| 트랜잭션이 필요한 작업 | 비동기 스레드는 별도의 트랜잭션 컨텍스트를 가진다 | DB 저장 후 즉시 후속 로직 실행이 필요한 경우 |
| 순서가 중요한 로직 | 비동기 처리 순서가 보장되지 않음 | 재고 감소 -> 주문 확정 -> 결제 승인 |
| 공유 자원 접근이 잦은 작업 | 동기화 비용이 커져 오히려 성능 저하 발생 | 공용 리스트나 Map을 동시에 수정하는 겨웅 |
| 결과가 즉시 필요한 작업 | 비동기 결과를 기다리면 결국 동기와 동일한 효과 | API 응답에 필요한 핵심 데이터 계산 |


### Fire-And-Forget 패턴
- 결과를 기다리지 않는 비동기 처리 방식
- 호출자는 요청을 보낸 뒤 응답을 기다리지 않고 즉시 다음 작업을 수행
- 사용자 경험 중심의 서비스에 적합

### 비동기 결과 결합 패턴
- 여러 비동기 작업을 동시에 수행한 뒤, 모든 결과가 완료되면 하나의 결과로 합치는 방식
- API 응답을 여러 외부 서비스에서 가져와 통합 데이터를 구성할 때 유용

### 배치 처리 패턴
- 배치 처리는 다수의 비동기 작업을 일정 단위로 묶어 한 번에 실행하는 방식
- 배치 처리는 대규모 데이터나 반복성 작업에 적합, 시스템 리소스를 효율적으로 활용할 수 있음

### 서비스 간 비도익 통신
- 이벤트 기반 아키텍처
  - 하나의 서비스가 이벤트를 발행하고 다른 서비가 구독하여 반응하는 구조
  - 서비스 간 직접적인 호출이 아닌 이벤트를 매개로 한 간접적인 연결 방식
- 이벤트 구성 요소
  - Event : 실제로 전달되는 데이터 단위
  - Publisher : 이벤트를 발행하는 서비스
  - Subscriber : 이벤트를 수신하고 처리하는 서비스
  - Event Bus : 이벤트를 전달하는 매개체 (메시지 브로커 역할)
 
- 메시지 큐
  - 생산자와 소비자 간의 통신을 중재하는 버퍼 역할
 
- 폴링과 웹훅
| 항목 | 폴링 | 웹훅 |
|-|-|-|
| 동작 방식 | 클라이언트가 일정 주기로 서버에 데이터 요청 | 서버가 이벤트 발생 시 클라이언트로 직접 전송 |
| 트래픽 효율성 | 낮음(주기적 요청 필요) | 높음 (이벤트 발생 시점에만 전송) |
| 구현 난이도 | 간단함 | 다소 복잡함(보안,콜백 관리 필요) |
| 사용 예시 | 실시간 채팅 메시지 확인 | 결제 성공 알림, 깃허브 푸시 알림 |


### 캐시
- 자주 접근하는 데이터를 빠르게 가져오기 위해 임시로 저장해두는 저장소
  - DB로 향하는 요청량을 크게 줄이고, 시스템 전체가 안정적으로 작동할 수 있음
- 목적
  - 자주 접근하는 데이터의 빠른 검색
  - 원본 데이터 소스의 부하 감소
  - 네트워크 지연 시간 최소화
 
### 캐시 핵심 원리
- 시간적 지역성
  - 최근에 사용한 데이터는 가까운 미래에도 다시 사용될 가능성이 높다
- 공간적 지역성
  - 어떤 데이터가 사용되면 그 주변 데이터도 곧 사용될 가능성이 높다
- 캐시 히트와 캐시 미스
- 캐시 적중률
  - 적중률이 낮다면 TTL이 너무 짧거나, 캐시할 데이터 선정이 잘못되었을 가능성이 있음
  - 변경이 잦을 경우 오히려 캐시 오버헤드가 생길 수 있음

### 캐시 적용 고려사항
- 캐시 적합 데이터 식별
  - 조회 빈도가 많을 것
  - 변경 빈도가 적을 것
  - 최신 데이터가 꼭 필요하지는 않을 것
- 데이터 크기와 수명 주기
  - TTL : 캐시 데이터의 유효 시간
  - 일정 시간이 지나면 자동으로 삭제되어, 데이터의 최신성 유지
  - TTL이 짧으면 최신성 보장, 길면 효율적 성능 유지가 가능
- 일관성과 최신성의 균형
  - 캐시와 실제 데이터가 달라지면 캐시 불일치 문제 발생
  - DB 변경 시점과 캐시 갱신 시점의 일관성을 유지해야 함
  - 해결 전략
    - Cache Invalidation
    - Write-through
    - Background Refresh
- 캐시 전략 선택
  - Cache-aside(Lazy Loading)
  - Write-through
  - Write-behind
  - read-through
 
### 캐시 계층 구조
| 계층 | 위치 | 속도 | 용량 | 주 용도 |
|-|-|-|-|-|
| L1 | CPU, 애플리케이션 메모리 | 매우 빠름 | 작음 | 즉시 접근 가능한 데이터 캐싱 |
| L2 | 애플리케이션 외부(ex: Redis, Memcached) | 빠름 | 중간 | 여러 서버 간 공유 캐시 |
| L3 | CDN, DB 캐시, 프록시 서버 등 | 상대적으로 느림 | 큼 | 전역적 데이터 배포 및 캐시 |

### 캐시 토폴로지
- 로컬 캐시
  - 애플리케이션 내부 메모리에 데이터를 저장하는 캐시 구조
  - 가장 빠르게 데이터에 접근할 수 있음
  - 네트워크 호출이 없어 응답 속도가 가장 빠름
  - 단순 구현 가능
  - 외부 장애에 영향 받지 않음
  - 서버마다 캐시가 달라 데이터 불일치 가능성
  - 서버 재시작 시 캐시가 모두 초기화
  - 확장성이 낮음
 
- 분산 캐시
  - 여러 서버 인스턴스가 동일한 캐시 서버를 공유하는 구조
  - 여러 서버가 하나의 중앙 캐시 저장소를 공유
  - 캐시 서버 장애 시에도 Persistence 설정 가능
  - 수평 확장에 유리함
  - 네트워크 지연이 존재
  - Redis 장애 시 모든 요청이 DB로 몰릴 수 있음
  - 운영/모니터링 복잡도가 증가
 
- 다중 레벨 캐시
  - L1+L2 구조
  - L1 캐시에서 데이터 검색 -> 없으면 L2
  - L2에서도 없으면 DB에서 조회 후 L1, L2 모두 저장
 
### 캐시 솔루션
- 인메모리 캐시 솔루션
  - 애플리케이션 내부 메모리에 데이터를 저장
  - 지연이 거의 발생하지 않으며, 로컬 캐시로 분류 됨
  - Caffeine, Guava Cache, EhCache
 
- 분산 캐시 솔루션
  - 외부 서버에 데이터를 저장하고 여러 애플리케이션 인스턴스가 공유하는 구조
  - Redis, Memcached
 
- 특화 캐시
  - HTTP 캐시는 웹 애플리케이션 레벨에서 정적 콘텐츠를 캐싱하는 방식
 
- ORM 캐시
  - JPA/Hibernate같은 ORM이 SQL 결과를 내부에 캐싱하여 DB 접근을 최소화하는 전략
 
### 캐시 아키텍처
- 트래픽 패턴 분석
  - 요청이 어디서 얼마나 자주, 어떤 시간대에 집중되는 지 파악
- 데이터 액세스 패턴 분석=
  - 데이터가 얼마나 자주 재사용되는지 분석
  - 읽기 중심, 쓰기 중심, 균형형
 

### Spring Cache
- Spring Cache 추상화는 여러 종류의 캐시 구현체를 일관된 방식으로 사용할 수 있게 해주는 통합 계층
- 캐시 로직을 AOP 기반으로 자동 적용.
- 어노테이션을 붙이는 것만으로 선언적 캐시 관리가 가능

### CacheManager
- 캐시 저장소를 생성하고 관리하는 관리자 역할
  - 캐시 등록 및 조회
  - 캐시 구현체 선택
  - 캐시 일관성 유지
 
### Cache
- Cache인터페이스는 캐시 데이터의 CRUD를 담당하는 핵심 컴포넌트
- 실제로 캐시 데이터를 저장하거나 읽어오는 작업은 Cache 객체 내부에서 이루어짐
  - get() 캐시에서 값 조회
  - put() 캐시에 새로운 값 저장
  - evict() 특정 키의 캐시 삭제
  - clear() 모든 캐시 데이터 삭제
 
### CacheResolver
- 복수의 캐시가 존재하는 환경에서, 어떤 캐시를 사용할 지 동적으로 결정하는 역할

### Cache 동작 원리
- 내부적으로 AOP를 이용하여 캐시 로직을 자동으로 처리
- 중복되지 않기 위해 커스텀 키 생성 가능
  - keyGenerator 구현


### Spring Cache 활성화
- @EnableCaching
- @cacheable
- @CachePut
- @CacheEvict
- @Caching
- @CacheConfig

### 복합 키
- 여러 파라미터를 결합하여 고유한 캐시 키를 만드는 방법
- 이 방식은 사용자 별 주문 정보 캐시와 같이 다중 속성을 구분해야 할 때 유용


### 로컬 캐시 최적화
- 무한정 데이터를 쌓을 경우 메모리 과다 사용으로 이어질 수 있음
- 크기제한, 만료정책, 제거 이벤트 처리를 적절히 조합해야 함

- 문제점
  - 메모리 부족
  - 오래된 데이터 유지로 인한 불일치
  - 캐시 적중률 하락으로 인한 DB 부하

- 만료 정책 설정
  - 시간 기반 만료
  - 접근 기반 만료
 
- 제거 이벤트 감지

### 캐시 문제
- 캐시 폭발
  - TTL 만료 : 캐시가 동시에 만료되어 모든 요청이 DB로
  - Lock 미적용 : 캐시가 비어 있을 때 여러 요청이 동시에 DB 접근
  - 대용량 트래픽 : 인기 데이터의 만료 시점에 요청 폭증
- 캐시 누수
  - 캐시가 더 이상 사용되지 않는 데이터를 계속 메모리에 보관하여 Heap 메모리 부족을 유발하는 현상
  - TTL 미설정 : 캐시 항목이 영구적으로 메모리에 남음
  - 크기 제한 누락 : 캐시 최대 크기가 없어 무한히 저장됨
  - 약한 참조 미사용 : GC가 캐시 항목을 해제하지 못함
- 캐시 오염
  - 자주 사용되지 않는 데이터가 캐시에 저장되어, 자주 사용하는 데이터가 밀려나는 현상
  - LRU 정책 한계 : 접근 빈도가 낮은 항목이 최근 접근으로 인해 유지 됨
  - 캐시 Key 설계 오류 : 비효율적인 Key 생성으로 동일 데이터 중복 저장
  - 인기 데이터 식별 실패 : 중요한 데이터가 우선순위를 받지 못함.
- 무한 캐싱
  - 캐시 항목에 TTL이 설정되지 않아 데이터가 영구적으로 저장되는 현상
  - TTL 설정 누락 : 캐시 항목이 만료되지 않음
  - 정적 데이터로 오인 : 업데이트 주기가 존재하는 데이터에 TTL 미적용
  - 모니터링 부재 : 캐시 사용량 증가를 인지하지 못함
 
### 분산캐시의 필요성
- 서버 간 데이터 일관성을 유지할 수 있고, 확장성과 안정성이 뛰어남
- 로컬 캐시의 한계
  - 서버마다 캐시가 서로 독립적으로 존재
  - 한 서버에서 데이터가 갱신되어도 다른 서버의 캐시는 오래된 데이터를 유지
  - 서버가 재시작되면 캐시 데이터가 초기화되어, DB 부하가 일시적으로 급증
 
- 다중 서버 환경에서의 데이터 일관성 문제
  - 데이터 불일치
  - 동시성 문제
  - 복구 지연
  - -> 서버간 캐시 공유 구조가 필요
 
- 서버 간 캐시 공유 메커니즘
  - 분산 캐시는 모든 서버가 공통 캐시 저장소에 접근하여 데이터를 읽고 저장
  - 모든 서버가 동일한 캐시 데이터를 공유
  - 한 서버가 데이터를 변경하면 즉시 모든 서버에 반영됨
  - 서버를 추가해도 캐시 일관성이 깨지지 않음
 
- 확장성과 고가용성 요구사항
  - 확장성
    - 서버 수가 증가하더라도 데이터는 중앙에서 관리되므로, 부하를 균등하게 분산할 수 있음
    - Redis Cluster나 Sharding 기법을 통해 대규모 트래픽을 처리할 수 있음
   
  - 고가용성
    - 분산 캐시는 마스터-슬레이브 구조를 통해 장애 시에도 서비스 중단 없이 운영됨
    - 장애 감지와 자동 복구를 지원
    - 안정적 서비스 운영의 핵심 인프라
   
- 고려사항
  - 네트워크 비용 고려
    - 캐시 접근이 로컬 메모리가 아닌 네트워크를 거치므로, 지연이 발생
    - 이를 완화하기 위해 로컬 캐시 + 분산 캐시 병행 구조를 자주 사용
   
  - TTL 정책의 중요성
    - 분산 캐시에도 TTL을 설정하지 않으면, 오래된 데이터가 계속 남아 데이터 불일치를 초래할 수 있음
    - 각 항목별 TTL을 비즈니스 요구사항에 맞게 세밀하게 조정해야 함
   
  - 장애 시 복구 전략
    - Redis 서버 장애 시를 대비해 Replica 구성과 Persistence(RDB, AOF) 설정이 필요함
    - 장애 발생 시 자동 복구되도록 Sentinel 기반 모니터링을 구성
   
### Redis
- 데이터를 메모리에 저장하는 초고속 인메모리 데이터 저장소
- 디스크 기반 데이터베이스보다 훨씬 빠르게 데이터를 읽고 쓸 수 있으며, 캐시, 세션 저장소, 실시간 순위 집계 등 다양한 분야에서 사용 됨
- 모든 데이터를 메모리에 저장하고, 필요할 때 디스크에 백업.
  - 속도는 메모리급, 안정성은 디스크급으로 설계되었음
 
- 싱글 스레드 기반의 고성능 구조
  - 단일 스레드 구조로 동작.
    - 한 번에 한 명령만 처리하지만, 논블로킹 I/O 모델을 통해 초당 수십만 건의 요청을 처리할 수 있음
  - 장점
    - 경쟁 조건 없음
    - Context Switching 없음
    - 높은 처리량
   
- 데이터 구조
  - String
  - List
  - Set
  - Sorted Set(ZSet)
  - Hash
  - Bitmap / HyperLogLog
 
- 영속성
  - 인모메리 시스템이지만, 데이터를 잃지 않기 위해 두 가지 영속성 옵션을 제공
  - RDB
    - 일정 주기로 전체 데이터를 스냅샷 형태로 디스크에 저장
    - 서버 재시작 시 마지막 스냅샷을 불러 옴
   
  - AOF
    - 모든 쓰기 명령(SET, LPUSH 등)을 순차적으로 파일에 기록
    - 장애 발생 시 명령을 다시 실행하여 복구
   
  - RDB+AOF 혼합 전략
    - 두 방식을 병행하여, 속도와 안정성의 균형을 맞출 수 있음
   
- Redis Cluster
  - MasterNode  실제 데이터 저장 및 요청 처리
  - Replica Node Master 복제본 유지, 장애 시 승격
  - Slot 데이터를 해시 기반으로 분산 저장
  - 클러스터는 자동으로 데이터 샤딩을 수행하여 부하를 분산
 
- Sentinel 기반 고가용성
  - Sentinel은 Redis 서버 상태를 모니터링 하고, 장애 발생 시 자동으로 복구
 
### 분산 캐시 패턴
- Look-Aside Cache Pattern(Lazy Loading)
  - 애플리케이션이 먼저 캐시를 조회하고, 없을 경우 DB를 직접 조회하여 캐시에 적재하는 방식
  - 간단한 구조, 캐시 장애 시 DB로 자동 폴백 가능
  - 최초 요청 시 지연 발생
  - 조회 빈도가 높은 정적 데이터에 적합
 
- Wirte-Through Cache Pattern (Synchronous Write)
  - 애플리케이션이 데이터를 저장할 때 캐시와 DB에 동시에 반영하는 방식
  - 항상 캐시와 DB가 일관된 상태 유지
  - 쓰기 작업이 느려질 수 있음 (동기 I/O)
  - 데이터 무결성이 중요한 환경(ex: 금융 트랜잭션) 에 적합
 
- Write-Behind Cache Pattern (ASynchronous Write)
  - 캐시에 먼저 쓰고, 일정 시간이 지난 후 DB에 반영하는 비동기 방식
  - 빠른 응답, 쓰기 집중 시스템에 유리
  - 장애 시 DB 반영 누락 가능성
  - 로그성 데이터, 통계 데이터 등 일시적 지연 허용 가능 환경에 적합
 
### 분산 캐시 고려사항
- 네트워크 지연과 오버헤드
  - 캐시 접근 속도는 네트워크 품질에 크게 영향을 받음
  - 지연의 원인
    - 네트워크 거리 : 서버 간 물리적 거리가 멀수록 RTT가 증가
    - 부하 집중 : 특정 노드에 트래픽이 집중되면 큐잉 지연이 발생
    - DNS 및 라우팅 지연 : 클러스터 내부 통신 경로가 복잡할수록 응답 시간이 늘어 남
   
  - 성능 최적화 방안
    - 로컬 캐시
    - Connection Pool 재사용
    - 파이프라이닝
    - 압축

- 데이터 일관성 관리
  - 캐시 데이터와 원본 데이터의 불일치
  - 해결 전략
    - TTL 설정
    - Write-Through
    - Cache Aside
    - Pub/Sub 동기화
   
- 장애 대응 전략
  - 장애가 발생하면 서비스 전체의 병목으로 이어질 수 있음
  - 장애 유형
    - 캐시 서버 다운
    - 네트워크 단절
    - Redis 재시작
   
  - 복구 전략
    - Replication(복제)
    - persistence
    - Sentinel 모니터링
    - Cluster 모드
   
- 보안 고려사항
  - 주요 보안 항목
    - 인증
    - TLS 암호화
    - 접근 제어
    - 데이터 마스킹
