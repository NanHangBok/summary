# DAY 105

## 목차
- [Let's Encrtpy](#let's-encrypt)
- [웹 인프라스트럭처](#웹-인프라스트럭처)
- [분산 시스템 등장](#분산-시스템-등장)
- [현대 웹 아키텍처](#현대-웹-아키텍처)
---

## Let's Encrypt
- 무료로 TLS/SSL 인증서를 발급하는 공인 인증 기관
- 웹 보안 표준을 강화하기 위해 비영리 단체 ISRG가 운영
- 비용 없이 SSL 인증서 발급 가능
- 브라우저가 신뢰하는 공식 CA
- 자동 발급 및 자동 개신 (ACME 프로토콜)
- 운영 서버용 (로컬 개발은 mkcert)

- ACME 프로토콜
  - ACME 프로토콜을 토해 인증서를 자동 발급 및 갱신
  - 도메인 소유자가 맞는지 검증하는 방식
  - HTTP-01
    - 서버에 임시 파일 생성하여 인증
   
  - DNS-01
    - DNS TXT 레코드 생성하여 인증(와일드카드 도메인 가능)
   
  - TTLS-ALPN
    - 특정 TLS 핸드셰이크 검사
   
- 필요성
  - 데이터 암호화
  - SEO 향상
  - 신뢰성 확보
  - 운영 자동화
 
## 웹 인프라스트럭처
- 초기 웹 (단일 서버 구조)
  - 모든 페에지가 정적 HTML 파일로 구성되어 있었음
  - 요청을 받으면, 서버가 단순히 HTML 파일을 찾아 응답
  - 데이터베이스나 복잡한 비즈니스 로직은 존재하지 않음
  - 구현이 간단하고 빠름
  - 서버 부하가 적음
  - 유지보수가 쉬움
  - 문제
    - 확장성 부족
      - 트래픽이 증가하면 CPU, 메모리, 네트워크 모두 한계에 부딪힘
      - 하드웨어를 업그레이드 하는데 물리적 한계와 높은 비용이 발생
    - 가용성 문제
      - 서버가 다운되면 서비스 전체가 중단 됨
      - 장애 복구 시간이 길어질수록 사용자는 이탈함
    - 병목 현상
      - 한 서버에 모든 요청이 몰리면 응답 지연이 발생
      - 특히 DB와 애플리케이션 로직이 같은 서버에 있으면 I/O 부하가 급증
    - 유지보수 어려움
      - 서버 한 대에 모든 기능이 얽혀 있어, 수정 시 전체 서비스에 영향을 미침
     
  - 초기 대응
    - 하드웨어 스펙 업그레이드
    - 정적 파일 캐싱
    - DB 쿼리 최적화 및 인덱싱
    - 간단한 로드 분산
   
## 분산 시스템 등장
- 수직적 확장의 한계
  - 단일 서버 구조에서 성능을 높이기 위한 가장 직관적인 방법은 하드웨어를 업그레이드 하는 것
  - CPU 코어를 늘리고, 메모리를 확장하며, 디스크를 SSD로 교체하는 방식
  - 물리적 한계 : CPU나 RAM을 무한히 늘릴 수 없음
  - 비용 한계 : 고성능 장비일수록 단가가 기하급수적으로 상승
  - 리스크 집중 : 서버 한 대에 모든 서비스가 집중되므로, 장애 발생 시 전체 서비스 중단
 
- 수평적 확장의 개념
  - 동일한 역할을 하는 서버를 여러 대 추가하여, 부하를 분산시키는 방식
  - 핵심 목표
    - 확장성 확보
    - 가용성 향상
    - 성능 개선

- 새로운 문제
  - 트래픽 분산 : 어떤 서버가 어떤 요청을 처리할지 결정해야 함 (로드밸런서 필요)
  - 세션 관리 : 사용자가 로그인된 상태를 여러 서버 간에 공유해야 함
  - 데이터 일관성 : 여러 서버가 같은 데이터를 동시에 접근할 때 동기화 필요
  - 장애 감지 및 복구 : 특정 서버가 다운되었을 때 자동으로 트래픽을 우회해야 함
 
- 트래픽 분산
  - 수평적 확장의 핵심은 로드 밸런싱
  - 로드 밸런싱 알고리즘
    - Round Robin : 요청을 순차적으로 분배
    - Least Connection : 현재 연결 수가 가장 적은 서버로 분배
    - IP Hash : 클라이언트 IP 기반으로 동일 서버로 연결 유지
   
  - 세션 관리
    - 서버가 여러 대일 경우, 사용자가 로그인한 세션이 서버마다 다를 수 있음
    - 해결방법
      -  Sticky Session : 동일 사용자의 요청을 항상 같은 서버로 연결 (IP 기반 고정)
      -  Session Clustering : 서버 간에 세션 정보를 공유 (Redis 세션 저장소)
      -  Stateless 방식 : 세션을 서버에 저장하지 않고, 클라이언트에 JWT 형태로 저장
     
  - 데이터 일관성
    - 동시에 수정 시 Race Condition 발생
    - 캐시 서버와 DB 간 데이터 불일치
    - 이를 해결하기 위해 분산락, Eventual Consistency 개념 도입
   
## 현대 웹 아키텍처
- 클라이언트-서버 모델
  - 초기의 웹 구조는 단순히 클라이언트와 서버 간의 통신 구조
  - 시간이 지남에 따라 클라이언트의 역할이 확장되고, 서버는 점점 복잡한 비즈니스 로직과 데이터 처리를 담당하게 됨
 
- 다계층 아키텍처
  - 표현 계층
    - 사용자의 요청을 입력받고, 응답을 출력하는 계층
   
  - 애플리케이션 계층
    - 핵심 비즈니스 로직 담당
  - 데이터 계층
    - 데이터를 저장하고 조회하는 역할
   
- 분산 시스템
  - 일관성, 가용성, 파티션 내성을 동시에 100% 만족할 수 없다는 것을 CAP 이론이라고 함
  - 일관성 + 파티션 내성 : CP / 은행 거래 시스템
  - 가용성 + 파티션 내성 : AP / SNS 피드
 
## 부하 분산기
- DNS -> L4 -> L7 순
- DNS
  - 하나의 도메인에 여러 개의 IP 주소를 등록
  - DNS 서버가 순차적으로 IP를 응답하는 방식
  - 장점
    - 단순성 : 별도의 장비 없이 DNS 만으로 트래픽 분산 가능
    - 저비용 : 소프트웨어 기반으로 구현 가능
    - 확장 용이 : 서버 IP를 추가 등록하면 됨
   
  - 한계
    - DNS 캐싱 문제 : 클라이언트나 ISP DNS에 IP가 캐싱되어 실제 분산 효과 저하
    - 상태 감지 불가 : 장애 서버가 있어도 계속 IP 응답
    - 불균등 트래픽 분배 : DNS TTL 차이로 특정 서버에 트래픽 집중 가능
   
  - 지리적 부하 부산
    - 사용자의 지리적 위치에 따라 가까운 서버의 IP를 반환하는 기술
   
- L4 부하 분산 (전송 계층)
  - OSI 4계층에서 TCP/UDP 패킷 단위로 트래픽을 분산
  - 실제 데이터가 흘러가는 경로 중간에 서서 요청을 받아 다른 서버로 전달
  - 동작원리
    - 클라이언ㅌ의 TCP 연결 요청을 L4 LB가 먼저 수신
    - LB는 트래픽 분배 알고리즘에 따라 서버를 선택
    - 선택된 서버로 패킷을 전달하고, 응답을 클라이언트에게 전달
    - L4 LB는 해킷 헤더 정보(IP, Port, 프로토콜) 만 보고 판단
   
  - 주요 기능
    - TCP/UDP 분산
    - Health Check
    - 세션 유지
    - 고성능 처리
   
- L7 부하 분산
  - 애플리케이션 계층에서 동작하며 요청의 내용(URI, 쿠키, 헤더, 파라미터 등)을 기반으로 분산
  - 주요 기능
    - 콘텐츠 기반 라우팅
    - SSL 종료
    - HTTP 헤더 조작
    - 부하 모니터링
   
## 부하 분산 알고리즘
- 라운드 로빈
  - 서버 목록을 순서대로 반복하면서 요청 분배
  - 단순하고 균등 분배가 쉬움
  - 각 서버의 현재 부하를 고려하지 못함
 
- 가중 라운드 로빈
  - 서버의 성능/ 스펙에따라 가중치를 부여하여 요청 분배 비율을 조정
  - 서로 다른 CPU/메모리 스펙 서버 혼재 시
 
- 최소 연결
  - 현재 활성 연결 수가 가장 적은 서버로 라우팅
  - 장기 연결이 섞인 환경에서 유리
 
- IP 해시
  - 클라이언트의 소스 IP를 해싱하여 특정 서버에 항상 동일하게 매핑
  - 세션 고정 효과(간접적인 Sticky)
 
- 응답 시간 기반
  - 백엔드 서버들의 실시간 응답 지연, 오류율, 큐 길이 등을 관찰하여 더 응답이 빠른 서버에 가중치를 높게 부여하고,
    - 느리거나 에러가 많은 서버의 가중치를 낮추거나 제외하는 방식
   
## 부하 분산기 한계
- 웹 인프라 대부분 L4 혹은 L7 부하 분산기를 중심으로 설계
- 이미지, 영상, 정적 콘텐츠의 증가로 인해 전송 효율성 문제
- 보안 공격이 지능화되며 단순 분산 이상의 방어 계층이 필요해짐
- 구조적 한계
  - 하드웨어 의존성 : 대부분 고가의 전용 장비로 구성되어, 확장성과 유연성이 떨어짐
  - 콘텐츠 처리 한계 : 캐싱, 압축, 이미지 리사이징 등 고성능 처리 기능이 제한적
  - 운영 복잡성 : 구성 변경 시 재시작이 필요하거나, 설정 관리가 복잡해짐
  - 보안 취약성
  - 비용 문제
- 정적 리소스
  - 캐싱 : 동적 컨텐츠에는 적용이 어려움
  - 압축 : Gzip, Brotli 등 압축 알고리즘을 지원하지만, 부하 분산기 자체의 CPU 부하가 급증
  - 콘텐츠 최적화 : 해상도별 이미지 제공이나, CDN 수준의 최적화가 불가능
 
- 서버 보호 측면
  - 대량 요청 폭주
  - 악의적 요청 필터링 한계
  - 비정상 트래픽 차단 불가
 
- 관리 및 확장성의 복잡성
  - 현대적인 인프라는 단순히 부하 분산기를 사용하는 대신, 애플리케이션 게이트웨이, 리버스 프록시, API Gateway, CDN 등을 조합하여 역할을 분리
 
## 리버스 프록시
- 로드 밸런서와 웹 서버 사이의 새로운 계층의 필요성
  - 보안 취약성
  - 성능 저하
  - 확장성 한계

- 등장 배경
  - 트래픽 증가 -> 서버 과부하
  - 보안 위협 증가 -> 서버 IP 노출, 직접 공격 위험
  - HTTPS/TLS 인증서 관리 복잡성
  - 여러 서버 간의 요청 분산 필요성
  - 서버 앞단에서 요청을 대신 받아 처리하는 중개자 -> 리버스 프록시

- 역할
  - 보안 보호 : 서버 IP 노출 방지 / 외부에서 실제 서버 위치를 알 수 없게 함
  - 접근 제어 : 방화벽과 연계 / 허용된 경로만 서버로 전달되도록 제한
  - 캐싱 : 정적 자원 캐싱 / 이미지, CSS, JS 파일 등을 프록시에서 직접 응답하여 서버 부하를 줄임
  - 압축 : 트래픽 절감 / 응답 데이터를 gzip 등으로 압축하여 전송량을 줄임
  - SSL 종료 : 암호화 복호화 담당 / 서버 대신 HTTPS 트래픽의 암복호화를 처리
 
- 리버스 프록시, L7 로드 밸런서
  - 공통점
    - 둘 다 L7 에서 동작
    - HTTP 헤더, URL, 쿠키 등을 기반으로 요청을 제어할 수 있음
    - 여러 백엔드 서버로 트래픽을 분산
   
  - 차이점
| 구분 | 리버스 프록시 | L7 로드 밸런서 |
|-|-|-|
| 주요 목적 | 보안 및 최적화 | 트래픽 분산 |
| 사용 위치 | 주로 내부망 앞단 | 외부/내부 경계에서 모두 사용 |
| 세션 관리 | 클라이언트와 서버 사이의 중개자 역할 | 요청을 여러 서버에 나눔 |
| 캐싱 기능 | 있음 | 일반적으로 없음 |
| SSL 처리 | 가능 | 일부 가능 |

#### 주요 기능
- 로드 밸런싱
  - 여러 대의 서버에 트래픽을 분산시켜 부하를 고르게 분배
 
- SSL 종료
  - HTTPS 암호화 트래픽을 리버스 프록시에서 복호화하고, 내부 서버로는 HTTP 평문으로 전달하는 방식
  - 실제 웹 서버가 SSL 인증서 관리나 암호화/복호화 연산 부담을 덜어 줌
  - 민감 데이터 전송 시 내부망도 HTTPS로 구성하는 것이 안전
 
- 캐싱 및 압축
  - 정적 자원을 캐싱하여 웹 서버로의 요청을 줄이고, 응답 데이터를 압축해 네트워크 대역폭을 절감
 
- 서버 보안 강화
  - 리버스 프록시는 웹 서버를 외부로부터 직접 노출하지 않게 하여 보안을 강화
  - 악의적인 요청이나 공격 패턴을 필터링할 수 있음
 
#### 구현
- 단일 프록시
  - 구성 간단, 설정 용이
  - 단일 장애 지점 존재
  - 트래픽 증가 시 확장성 한계
 
- 다단계 프록시 구성
  - CDN -> WAF -> 리버스 프록시 -> 백엔드 서버 구조
  - 보안, 성능, 확장성 모두 확보
  - 장애 대응이 뛰어남
  - 각 계층이 독립적으로 확장 가능
  - HTTPS, 캐시, WAF 정책을 분리 가능
 
- 클라우드형 리버스 프록시
  - 클라우드 기반 리버스 프록시/CDN 통합 구조 사용
  - 빠른 개발이 필요할 때
  - 전 세계 CDN 캐싱으로 대기 시간 최소화
  - SSL/TLS 인증 자동 관리
  - 서버가 다운되더라도 다른 리전에 자동 라우팅
 
## API 게이트웨이
- 마이크로서비스 아키텍처를 지탱하는 핵심 구성 요소
  - 리버스 프록시와 로드 밸런서의 한계
    - 복잡한 라우팅 한계
    - API 버전 관리 부재
    - 인증/인가 중앙화 불가
    - 서비스 검색
    - 모니터링 부재
   
- 모놀리식 구조의 코드 배치
  - 하나의 거대한 애플리케이션 안에 모든 기능이 통합된 형태
  - 배포 리스크 : 코드 한 줄 수정 시 전체 서비스를 재배포 해야 함
  - 확장성 한계 : 특정 기능만 트래픽이 많아도 전체 서버를 증설해야 함
  - 기술 스택 제약 : 모든 기능이 동일한 언어/프레임워크를 사용해야 함
  - 팀 간 충돌 : 하나의 코드베이스에서 여러 팀이 동시에 수정 시 충돌 빈번
 
- 마이크로서비스
  - 각 서비스는 독립적인 데이터베이스와 배포 주기를 가질 수 잇음
    - 각 서비스의 엔드포인트를 클라이언트가 모두 알아야 함
    - 인증/인가, 로깅, 속도 제한, 버전 관리 등 공통 기능이 중복 구현 됨
  - 이 때 등장한 해결책이 바로 API 게이트웨이
 
- 핵심 기능
  - 모든 클라이언트 요청의 진입점으로 동작
  - 서비스 전반을 조정하고 보호하는 중앙 통제 시스템으로 작동
  - 라우팅 및 엔드포인트 통합
    - 마이크로서비스로 랄우팅
    - 하나의 게이트웨이 주소로 요청을 보내면, 게이트웨이가 내부적으로 라우팅을 수행
   
  - 인증 및 권한 부여
    - 게이트웨이에는 인증 전용 필터를 두는 것이 일반적
    - JWT 만료 시 Refresh Token 정책을 통해 토큰을 재발급하도록 구성
   
  - 속도 제한 및 할당량 관리
    - 사용자의 요청 빈도를 제한하여, 서버가 과부하에 걸리지 않도록 보호
    - 고정 윈도우 : 일정 시간 단위에 n회 허용
    - 슬라이딩 윈도우 : 시간 단위를 유동적으로 계산
    - 토큰 버킷 : 요청 시마다 토큰을 소모하고, 일정 주기로 재충전
    - 속도 제한 정책은 서비스 유형별로 다르게 설정할 수 있음
   
  - 데이터 변환 및 프로토콜 변환
    - 게이트웨이 요청 또는 응답을 가공하여 클라이언트와 서버가 서로 다른 데이터 형식을 사용하더라도 통신이 가능하게 함
    - JSON <> XML 변환
    - HTTP <> gRPC 변환
    - 필드 매핑
   
  - 요청 집계 및 조합
    - 클라이언트가 여러 서비스를 동시에 호출해야 할 때,
   
  - 모니터링 및 분석
    - API 게이트웨이는 모든 요청을 통과하므로, 서비스 전체의 상태를 관찰할 수 잇는 최적의 위치에 있음
    - 요청 로그
    - 성능 지표
    - 알림 시스템 연동
      - 게이트웨이가 이를 대신 호출하고 결과를 하나의 응답으로 조합할 수 있음
     
## Nginx
- 고성능 HTTP 서버이자 리버스 프록시, 로드 밸런서, 스트림 프록시, API 게이트웨이 역할까지 수행할 수 있는 현대적 서버 플랫폼
- 이벤트 루프 기반 구조로 동작하여, 동시 여녁ㄹ이 많은 환경에서 매우 효율적

- 서버 블록
  - 요청을 받아들일 포트 및 도메인 정의
 
- location 블록
  - 특정 요청 경로에 대한 처리 방식을 정의
 
- 수행할 수 있는 역할
  - 웹 서버
  - 리버스 프록시
  - 로드 배런서
  - API 게이트웨이(기초 수준)
  - 캐싱 서버
 
## 포워드 프록시
- 전용선 비용과 대역폭 관리의 필요성
- 기업,교육기관의 접속 통제 요구
  - 직원이 업무와 무관한 사이트 접속 방지
  - 학생의 유해 콘텐츠 접근 차단
  - 특정 시간대만 인터넷 사용 허용
  - 로그를 남겨 보안 및 감사 수행
- 초기 프로시 서버의 등장
- 해결한 문제
  - 대역폭 부족 : 캐싱으로 중복 요청 제거
  - 접속 통제 어려움 : 인증,URL 필터링 적용
  - 관리,감시 필요 : 사용자 로그 기록
  - 보안 위협 : 악성 사이트 차단
 
- 클라이언트가 외부 인터넷에 직접 전근하지 않고, 프록시 서버가 대신 요청을 수행하고 응답을 전달해주는 구조

- 포워드 프록시 : 내부 -> 외부 요청 중개
- 리버스 프록시 : 외부 -> 내부 요청 중개

- 명시적 프록시
  - 클라이언트가 프록시를 명시적으로 지정해야 동작 -> 명시적 프록시
  - 의미
    - 외부 서버로 직접 요청하지 않겠습니다
    - 모든 요청을 프록시 서버에게 먼저 전달하겠습니다
    - 이 설정을 통해 조직은 사용자의 인터넷 트래픽을 통제 및 모니터링 할 수 있음
   

- 요청을 해석하고 검증하고 재구성한 뒤 외부 서버와 통신하고 응답을 반환하는 역할 수행
  - 요청 수신
    - 요청 헤더 분석
    - Host 도메인 확인
    - 요청 메서드 검증
    - 차단 도메인 또는 금지된 메서드 필터링
    - 사용자 인증 필요 시 인증 확인
   
  - 요청 재작성 및 전달
    - URL 정규화
    - 필수 헤더 추가
    - 불필요/위험 헤더 제거
    - HTTP -> HTTPS 업그레이드 가능
    - TLS핸드셰이크 중개
   
  - 목적 서버 요청 및 응답 반호나
    - 응답 헤더/본문 수신
    - 악성 콘텐츠 필터링 가능
    - 캐시 저장 가능
    - 최종 사용자에게 응답 전달
   
- 포워드 프록시 주요 기능 개용
  - 정책 적용, 보안 강화, 네트워크 최적화를 위해 활용 됨
  - 단순한 중계가 아닌 보안 게이트웨이 + 요청 제어 + 성능 최적화 시스템으로 기능
 
  - 익명성과 개인정보 보호
    - 실제 IP주소를 숨기고, 대신 프록시 서버의 IP로 외부 요청 수행
    - 사용자의 식별 정보가 외부 서비스에 직접 노출되지 않음
    - 개인정보 보호 및 위치 정보 보호가 가능
   
  - 접근 제어 및 콘텐츠 필터링
    - 특정 사이트가 서비스에 대한 접근 제한 정책 적용
   
  - 캐싱을 통한 성능 향상
    - 자주 요청되는 데이터를 캐싱하여 성능을 높임
      - 중복 요청 감소
      - 네트워크 대역폭 절약
      - 페이지 로딩 속도 향상
     
  - 지역 제한 우회
    - 지정된 국가/지역의 IP 주소를 사용해 사이트에 접속
    - 외부 서비스는 요청자의 IP 기반 지역 판별
    - 프록시 서버가 다른 나라에 위치 하면 해당 국가 사용자처럼 보임
   
- 현대 웹에서의 포워드 프록시
  - 개인정보 보호 및 익명성 강화
  - 기업 보안 및 트래픽 통제
  - 지역 제한 우회 및 접근 제어
  - 모바일 데이터 절약 및 콘텐츠 압축
 
- VPN과 프록시
| 구분 | 포워드 프록시 | VPN |
|-|-|-|
| 목적 | 특정 트래픽만 프록시 서버를 통해 전달 | 사용자의 전체 네트워크 트래픽 암호화 및 터널링 |
| 대상 레벨 | 앱/브라우저 단위 | OS/디바이스 저체 |
| 익명성 | 제공 가능 | 매우 강력 |
| 암호화 | 선택적(HTTP/HTTPS 프록시) | 기본적으로 전체 암호화 |
| 대표 사용 사례 | 사내망 접근 제어, 캐싱 | 공공 Wifi보호, 지역 우회, 개인정보 보호 |

- 보안 프록시
  - 수행 역할
    - 트래픽 모니터링 및 기록
    - 악성 사이트 차단
    - 데이터 유출 방지
    - TLS 복호화 및 검사
    - 사용자 인증
   
- 개인용 프록시 서비스
  - 개인정보 보호
  - 광고 및 트래커 차단
  - 특정 지역 콘텐츠 접근
  - 다중 계정 운영 시 추적 방지
 
- 모바일 프록시
  - 모바일 네트워크 특징
    - 압축 이미지 제공(데이터 절감 모드)
    - 광고 및 위험사이트 필터링
    - 아동 콘텐츠 보호 옵션 제공
   
- 포워드 프록시, 리버스 프록시
| 구분 | 포워드 프록시 | 리버스 프록시 |
|-|-|-|
| 위치 | 클라이언트 앞 | 서버 앞 |
| 주요 목적 | 외부 사이트 접근 통제, 캐싱, 익명화 | 서버 보호, 로드 밸런싱, SSL 종료 | 캐싱 |
| 클라이언트가 인식 | 프록시가 보임 | 서버가 보임, 내부 서버가 숨겨짐 |
| 요청 흐름 | Client->Proxy -> Internet -> Server | Client -> Reverse Proxy -> Internal Servers |
| 예시 | 사내 프록시, VPN Proxy, 웹 필터링 | Nginx, Apache, Envoy, Cloudflare |
